---
description: Four conditions gate self-healing — deterministic outcome, reversible via git, low cost if wrong, and proven accuracy at report level — and the trust boundary between fix and report should move
kind: research
topics: ["[[maintenance-patterns]]", "[[agent-cognition]]"]
methodology: ["Systems Theory", "Original"]
source: [[automated-knowledge-maintenance-blueprint]]
---

# the fix-versus-report decision depends on determinism reversibility and accumulated trust

When automated maintenance detects a problem, the system faces a binary choice: fix it or flag it. The temptation is to fix everything possible, because since [[automated detection is always safe because it only reads state while automated remediation risks content corruption]], the detection is already running and the fix seems like the natural next step. But the read/write asymmetry is precisely why this decision demands careful design. Detection that gets something wrong wastes attention. Remediation that gets something wrong corrupts content — and the corruption is invisible because the modified state becomes the ground truth that subsequent operations trust.

Four conditions must ALL hold before an automated system should fix rather than report. The first is determinism: the fix must have exactly one correct outcome. Index synchronization passes — there is one correct index state given the current files. Description rewriting fails — multiple valid descriptions exist for any note, and choosing among them requires reading the content and understanding what matters. The second is reversibility: the fix must be undoable, ideally through infrastructure that already exists. Auto-commit passes because git provides complete history. Note splitting fails because reassembling a split note requires the judgment that motivated the split. The third is low cost if wrong: an incorrect fix must be cheaper to correct than not fixing at all. Adding a schema field placeholder is cheap to fix (delete the wrong value) but expensive if the placeholder misleads future processing into treating it as real content. The fourth is accumulated trust: the automation must have operated correctly at the report level long enough to establish a track record.

This fourth condition — accumulated trust — is what distinguishes this claim from the determinism boundary alone. Since [[the determinism boundary separates hook methodology from skill methodology]], the determinism test asks a static question: does this operation require judgment? But the fix-versus-report decision adds a temporal dimension. An operation that is demonstrably deterministic still should not auto-fix on day one. It should report, accumulate evidence that its reports are accurate, and only then graduate to auto-fix. The trust boundary is a moving line, not a fixed one, and it should move leftward (toward more self-healing) only when observational data justifies the shift.

The vault's own operations illustrate the spectrum concretely, and since [[three concurrent maintenance loops operate at different timescales to catch different classes of problems]], the examples map directly onto the loop architecture where each timescale makes the fix-versus-report decision differently. At the self-healing end: qmd index sync is mechanical, always correct, and idempotent — running it twice produces the same index as running it once. Auto-commit after file writes preserves state, is fully reversible via git, and there is never a case where committing is the wrong action. These pass all four conditions trivially. In the middle: fixing a broken wiki link from a tracked rename can self-heal because git history provides the unambiguous correct target, the fix is deterministic and reversible, and the cost of a wrong rename resolution (pointing to the wrong note) is bounded by the ease of re-running the rename script. But fixing a broken wiki link from a deleted file should only report, because multiple valid responses exist — the link might need updating, removing, or replacing with a different note. At the report-only end: adding notes to MOCs, rewriting descriptions, splitting overgrown notes, and evaluating connection quality all require semantic judgment that varies with each invocation. No amount of accumulated trust should promote these to auto-fix, because they fail the determinism condition permanently.

Since [[confidence thresholds gate automated action between the mechanical and judgment zones]], the trust boundary operationalizes through the same three-tier response pattern: auto-fix above high confidence with demonstrated accuracy, suggest fixes at medium confidence, and report-only below. The key insight is that the threshold itself should drift lower over time as evidence accumulates — but the drift must be evidence-based, not assumption-based. A system that reported broken-rename links correctly for 200 consecutive cases has earned a lower fix threshold than a system deployed yesterday. Since [[methodology development should follow the trajectory from documentation to skill to hook as understanding hardens]], this is the same patience principle: report-first is the documentation stage where the system learns, conditional-fix is the skill stage where understood patterns get encoded, and unconditional-fix is the hook stage where the pattern has been confirmed through extensive operational experience.

The shadow side is that the trust boundary creates pressure toward eventual full automation. Each successful fix-promotion demonstrates that automation works, which generates pressure to promote the next candidate. Since [[over-automation corrupts quality when hooks encode judgment rather than verification]], the risk is that the boundary erodes past the point where determinism holds. The defense is that the four conditions are conjunctive, not disjunctive — failing ANY one blocks the promotion regardless of how well the others are satisfied. An operation that is perfectly deterministic, fully reversible, and extensively trusted but high-cost-if-wrong (like archiving notes that appear stale) should never auto-fix, because the cost condition acts as an independent veto. The conditions are not a sliding scale where strength in one compensates for weakness in another. They are a checklist where every box must be checked.

The trust boundary also needs a complementary lifecycle direction. Promotion is not the only transition — since [[automation should be retired when its false positive rate exceeds its true positive rate or it catches zero issues]], the full lifecycle runs from initial report through graduated promotion to eventual decommission. A check that was correctly promoted to auto-fix may later lose its justification as upstream improvements structurally eliminate the problem it guards against, or as methodology changes render the condition irrelevant. Without retirement criteria, the automation layer accumulates monotonically, and the conjunctive defense against over-promotion becomes less meaningful if the total number of automated checks grows without bound. The graduated promotion this note describes is only half the governance story — retirement completes it.

Even with careful gating, wrong fixes will occasionally occur. The critical question is whether those failures are visible. Because [[observation and tension logs function as dead-letter queues for failed automation]], a wrong auto-fix that corrupts a note produces evidence — an observation note capturing the discrepancy, a tension note flagging the conflict — rather than failing silently. This dead-letter infrastructure is what makes the graduated promotion from report to fix tolerable rather than reckless. Without it, every promotion is a bet with invisible downside. With it, the downside is bounded by the visibility guarantee: even when the trust boundary moves too far leftward, the failure is captured for the slow loop's meta-cognitive review to detect and correct.

---
---

Relevant Notes:
- [[the determinism boundary separates hook methodology from skill methodology]] — foundation: the determinism boundary asks whether an operation requires judgment, this note adds three further conditions (reversibility, cost, trust) that must also pass before automation should fix rather than merely report
- [[automated detection is always safe because it only reads state while automated remediation risks content corruption]] — complementary axis: the read/write asymmetry explains why detection needs no trust gate while remediation needs all four conditions; this note specifies what it takes for remediation to earn autonomous authority
- [[confidence thresholds gate automated action between the mechanical and judgment zones]] — operationalizes the trust dimension: confidence scoring provides the graduated mechanism through which trust accumulates, with empirical false positive rates determining when the boundary can shift
- [[idempotent maintenance operations are safe to automate because running them twice produces the same result as running them once]] — additional safety filter: even a deterministic, reversible, trusted fix must also be idempotent before safe scheduling, because hooks fire on events that repeat
- [[methodology development should follow the trajectory from documentation to skill to hook as understanding hardens]] — temporal parallel: the trust boundary moves leftward through the same patience-driven trajectory; report-first is the documentation stage, conditional fix is the skill stage, unconditional fix is the hook stage
- [[over-automation corrupts quality when hooks encode judgment rather than verification]] — the failure mode when any of the four conditions is violated: jumping to fix without accumulated trust produces confident systematic errors that metrics cannot detect
- [[three concurrent maintenance loops operate at different timescales to catch different classes of problems]] — provides the structural context where the fix-versus-report gradient maps onto different loop characters: the fast loop passes all four conditions trivially, the medium loop passes detection but not remediation, and the slow loop fails determinism for detection itself
- [[automation should be retired when its false positive rate exceeds its true positive rate or it catches zero issues]] — lifecycle complement: the trust boundary governs promotion from report to fix, retirement governs the opposite direction; together they define the full lifecycle of automation authority from initial deployment through graduated promotion to eventual decommission
- [[observation and tension logs function as dead-letter queues for failed automation]] — enables graduated promotion: the dead-letter pattern provides the safety net that makes trusting auto-fix less risky, because even wrong fixes produce visible evidence in the observation and tension logs rather than failing silently
- [[reconciliation loops that compare desired state to actual state enable drift correction without continuous monitoring]] — architectural context: reconciliation separates detection (always safe) from remediation (needs gating), and the four conditions here provide the specific gating criteria for each reconciliation remediation decision
- [[maintenance scheduling frequency should match consequence speed not detection capability]] — complementary dimension: consequence speed determines WHEN to detect, the four conditions determine WHETHER to fix what detection finds; together they parameterize the complete automation scheduling question

Topics:
- [[maintenance-patterns]]
- [[agent-cognition]]
