---
description: The same conceptual system (atomic notes, wiki links, MOCs, pipelines, quality gates) manifests differently on each platform because infrastructure determines which features can actually operate,
kind: research
topics: ["[[agent-cognition]]"]
methodology: ["Original"]
source: [[agent-platform-capabilities-research-source]]
---

# knowledge system architecture is parameterized by platform capabilities not fixed by methodology

The tempting assumption when building knowledge systems for agents is that the methodology defines a fixed architecture and each deployment replicates it. Atomic notes, wiki links, MOCs, processing pipelines, quality gates, maintenance cycles -- the system IS these things, so build them everywhere the same way. But this assumption breaks immediately on contact with real platforms because the methodology describes what to achieve while the platform determines what can actually operate.

The better frame is parameterization. Since [[knowledge systems share universal operations and structural components across all methodology traditions]], the conceptual system remains constant: the same eight operations (capture, structure, connect, process, synthesize, maintain, retrieve, evolve) and nine structural components (notes, schema, links, navigation, folders, templates, hooks, search, health) recur regardless of platform. These are the invariant goals. But since [[eight configuration dimensions parameterize the space of possible knowledge systems]], the implementation of each goal varies along specific dimensions — granularity, organization, linking, processing intensity, navigation depth, maintenance cadence, schema density, and automation level — and platform capabilities constrain which positions along each dimension are viable. Since [[platform capability tiers determine which knowledge system features can be implemented]], a full-automation platform (Claude Code) implements processing pipelines with fresh context per phase via subagent spawning, while a minimal-infrastructure platform implements the same pipeline goal through manual session boundaries. The methodology is identical, but the parameterization differs.

What makes this more than a deployment concern is that since [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]], the parameters are not arbitrary knobs but structured by layer. The foundation layer (files, conventions, wiki links) is invariant across all parameterizations because since [[local-first file formats are inherently agent-native]], the file IS the artifact and needs no infrastructure. Convention layer parameters adjust how instructions encode quality standards. Automation layer parameters determine whether enforcement is guaranteed (via hooks) or suggested (via instructions). Orchestration layer parameters control whether multi-phase coordination runs automatically or manually. A knowledge system generator that understands these layers can produce the maximum-quality system a given platform sustains rather than offering a degraded copy of a full-featured design.

The parameterization frame also explains why since [[platform adapter translation is semantic not mechanical because hook event meanings differ]], cross-platform portability is hard. Changing parameters is not flipping feature flags. A PostToolUse hook that validates schemas on every file write achieves three things: automatic firing, real-time feedback, and out-of-context-window execution. On a platform without per-operation hooks, the generator must decompose that guarantee and reconstruct each property through available mechanisms. Since [[configuration dimensions interact so choices in one create pressure on others]], the space of valid configurations is smaller than the combinatorial product of individual capabilities.

There is a productive tension with since [[complex systems evolve from simple working systems]]: parameterization is a design-time choice about starting configuration, but Gall's Law says complex systems must evolve from working simplicity. The reconciliation is that parameterization should target the simplest working configuration for each platform, then let evolutionary pressure add complexity where friction emerges. A generator that targets maximum complexity for a given platform violates Gall's Law even if the platform could theoretically support it. The generator's real job is producing the minimum viable parameterization that starts working, with enough platform knowledge embedded in the context file for the agent to extend the system when pain emerges.

The temporal dimension of parameterization reveals a deeper design constraint. Since [[methodology development should follow the trajectory from documentation to skill to hook as understanding hardens]], the initial parameterization should favor instruction-level encoding even on platforms capable of full automation. The generator produces a context file at the convention layer, and since [[self-extension requires context files to contain platform operations knowledge not just methodology]], that context file must include platform-specific construction knowledge so the agent can evolve the system upward through the layers as friction accumulates. This means parameterization determines not just the starting configuration but the evolutionary ceiling: since [[bootstrapping principle enables self-improving systems]], only tier-one platforms where the agent can modify its own context file and create infrastructure can close the recursive improvement loop. Lower-tier parameterizations produce systems that operate but cannot evolve.

The parameterization frame also clarifies why since [[platform fragmentation means identical conceptual operations require different implementations across agent environments]], the generator's cost structure is uneven. Foundation and convention parameters are write-once because they are platform-agnostic. Automation and orchestration parameters are write-per-platform because since [[skill context budgets constrain knowledge system complexity on agent platforms]], even platforms at the same tier impose different budget constraints that force different skill consolidation strategies. The generator must understand these constraints to produce viable parameterizations rather than theoretically complete ones that exceed platform budgets.

What remains invariant across all parameterizations is the conceptual architecture itself. Since [[coherent architecture emerges from wiki links spreading activation and small-world topology]], the foundational triangle -- wiki links as structure, spreading activation as traversal mechanism, small-world topology as structural requirement -- works identically whether the platform supports hooks and subagents or just reads files. The parameterization adjusts how the agent interacts with this invariant structure, not whether the structure exists. And since [[data exit velocity measures how quickly content escapes vendor lock-in]], the invariant layers have maximum portability while the parameterized layers introduce platform dependencies -- a gradient that the generator should make explicit so operators understand which features survive platform transitions.

---
---

Relevant Notes:
- [[platform capability tiers determine which knowledge system features can be implemented]] -- provides the tier framework (full, partial, minimal) that this claim generalizes into the parameterization principle
- [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]] -- provides the layer decomposition (foundation, convention, automation, orchestration) that defines what the parameters control
- [[local-first file formats are inherently agent-native]] -- explains why the foundation layer is invariant across parameterizations: plain text with embedded metadata works everywhere, so the parameters only affect upper layers
- [[complex systems evolve from simple working systems]] -- complements this from the temporal axis: parameterization determines the starting configuration, Gall's Law determines how it evolves on any given platform
- [[platform adapter translation is semantic not mechanical because hook event meanings differ]] -- reveals that parameterization is not just feature toggling but semantic translation: what a hook achieves on one platform may require a fundamentally different mechanism on another
- [[skills encode methodology so manual execution bypasses quality gates]] -- illustrates what gets lost when parameterization removes features: not convenience but the methodology itself
- [[context files function as agent operating systems through self-referential self-extension]] -- the context file is the primary carrier of parameterized output: what the generator produces is a context file whose self-extension capability itself varies by platform tier
- [[self-extension requires context files to contain platform operations knowledge not just methodology]] -- the content requirement that parameterization creates: universal methodology sections plus platform-specific construction manuals
- [[platform fragmentation means identical conceptual operations require different implementations across agent environments]] -- the implementation cost that makes parameterization necessary: if platforms were uniform, fixed replication would suffice
- [[methodology development should follow the trajectory from documentation to skill to hook as understanding hardens]] -- provides the temporal evolution path within a parameterized system: initial parameterization should start at instruction level and evolve upward as understanding develops
- [[bootstrapping principle enables self-improving systems]] -- parameterization constrains not just the starting configuration but the evolutionary capacity: only tier-one platforms can close the recursive improvement loop
- [[data exit velocity measures how quickly content escapes vendor lock-in]] -- exit velocity grades inversely with parameterization depth: foundation-layer parameters have maximum portability, orchestration-layer parameters have minimum
- [[skill context budgets constrain knowledge system complexity on agent platforms]] -- a concrete parameterization constraint: platform-enforced budgets force skill consolidation that reshapes how methodology gets encoded
- [[coherent architecture emerges from wiki links spreading activation and small-world topology]] -- the foundational triangle is what remains invariant across all parameterizations: the conceptual system that parameterization implements differently per platform
- [[storage versus thinking distinction determines which tool patterns apply]] -- upstream parameter: before selecting which patterns to parameterize, the generator must identify whether the target use case is primarily storage or primarily thinking; this determines which pattern catalog applies
- [[configuration dimensions interact so choices in one create pressure on others]] -- formalizes why parameterization is harder than setting independent knobs: dimension coupling means the valid configuration space is far smaller than the combinatorial product, so the generator must understand which parameter combinations form coherent operating points
- [[eight configuration dimensions parameterize the space of possible knowledge systems]] — concretizes the abstract parameterization this note describes: specifies the eight dimensions and their poles that the generator navigates
- [[knowledge systems share universal operations and structural components across all methodology traditions]] — provides the formal inventory of what remains invariant across parameterizations: the eight operations and nine structural components are the constants that dimensions parameterize and platforms implement differently

Topics:
- [[agent-cognition]]
