---
description: Dump first then structure within 24 hours — Ebbinghaus decay means capture context fades fast, so inbox processing should be time-prioritized not just manually triggered
kind: research
topics: ["[[processing-workflows]]"]
methodology: ["Cornell"]
source: TFT research corpus (00_inbox/heinrich/)
---

# temporal separation of capture and processing preserves context freshness

This is a design principle borrowed from Cornell Note-Taking and grounded in memory science. You do not fill in cues during the lecture; you do it immediately after. The reasoning is straightforward: context fades. The understanding you have at capture time — why something matters, how it connects, what sparked the insight — erodes rapidly once you move on to other things. Because [[every knowledge domain shares a four-phase processing skeleton that diverges only in the process step]], this temporal separation is specifically the gap between phase one (capture) and phase two (process) of a universal pipeline — and the Ebbinghaus constraint governs how long that gap can be before the process step loses the contextual understanding that makes domain-specific transformation effective.

The Ebbinghaus forgetting curve provides the scientific basis. Without reinforcement, memory retention drops exponentially: roughly 50% lost within the first hour, 70% within 24 hours. This means the window for processing captured content is measured in hours, not days. A note dumped this morning and processed tonight retains more of its original meaning than one left in the inbox for a week.

For agent-delegated processing, this means "dump first, structure later" comes with a time constraint. The dump is zero-friction capture — don't interrupt the flow, don't force structure at the moment of insight. But "later" doesn't mean "whenever." Later means soon enough that you still remember why you captured it. There's a middle path between pure dumps and full processing: since [[schema templates reduce cognitive overhead at capture time]], pre-defined fields can enable faster capture than freeform writing while preserving more structure than raw dumps. The schema externalizes structural decisions, so capture becomes "fill these boxes" rather than "design this note" — reducing capture-time overhead while context remains fresh. Research on guided notes extends this insight: since [[guided notes might outperform post-hoc structuring for high-volume capture]], skeleton outlines provided before capture may work even better for streaming content (lectures, conversations) where information arrives faster than you can process it. The schema approach fits discrete content (a book, an article); guided notes may fit flows where real-time categorization would compete with listening. This temporal separation has a potential cost: since [[does agent processing recover what fast capture loses]] tests whether the human loses encoding benefits when capture is fast and generation is delegated, the same Ebbinghaus decay that justifies urgency may mean the human never deeply encodes content that agents process for them. This adds a time dimension to [[throughput matters more than accumulation]] — throughput isn't just about how FAST you process but WHEN, because context freshness decays exponentially within the first day.

The agent implication is temporal triggers for inbox processing. Rather than only processing when manually invoked, inbox agents should prioritize by age. Since [[temporal processing priority creates age-based inbox urgency]] operationalizes this into a queue algorithm: notes under 24 hours are standard priority, 24-72 hours elevated, beyond 72 hours critical. Notes approaching 24 hours are urgent. Notes beyond 24 hours have already lost context — they're still worth processing, but the original understanding may be unrecoverable. This temporal prioritization extends beyond inbox processing: since [[spaced repetition scheduling could optimize vault maintenance]] tests whether newly created notes need more frequent verification than mature notes, the Ebbinghaus principle that grounds this inbox urgency may also ground review scheduling — recently created notes have higher issue rates (weak descriptions, missing connections) than notes that have survived multiple reviews.

There is a complementary urgency at a shorter timescale. Since [[Zeigarnik effect validates capture-first philosophy because open loops drain attention]], the moment a thought occurs and is not externalized, it becomes an open loop consuming working memory. Ebbinghaus governs the processing window — hours before context decays. Zeigarnik governs the capture window — seconds before the open loop begins draining attention. These are complementary urgencies: capture within seconds (close the loop), process within hours (preserve the context). A system that handles both timescales — zero-friction capture for Zeigarnik, temporal processing priority for Ebbinghaus — addresses the full temporal constraint on knowledge work.

This principle operates at a different level than [[fresh context per task preserves quality better than chaining phases]]. That claim addresses LLM context rot within sessions — later phases run on degraded attention, so each task gets isolation. This claim addresses human context decay between sessions — the human who captured the note loses context over time, so processing should happen before that decay sets in. Both principles point toward time-sensitivity, but for different reasons and at different scales.

The practical constraint for agent-operated knowledge systems: while the architecture supports prioritized processing, many implementations lack temporal triggers. Inbox items are processed in whatever order the operator chooses. Adding age-based priority to the orchestration layer or creating an inbox-triage skill that surfaces oldest items first would implement this principle fully. For now, it's a design decision that implementations should consider.
---

Relevant Notes:
- [[temporal processing priority creates age-based inbox urgency]] — operationalizes this principle into a queue algorithm: <24h standard, 24-72h elevated, >72h critical; converts the Ebbinghaus decay rationale into actionable scheduling logic
- [[fresh context per task preserves quality better than chaining phases]] — parallel principle at the agent level; this note addresses human context decay, that note addresses LLM context rot
- [[processing effort should follow retrieval demand]] — potential tension: demand-driven processing suggests delay, but Ebbinghaus suggests urgency
- [[throughput matters more than accumulation]] — this note adds the time dimension: throughput requires not just processing velocity but timely processing while context is fresh
- [[the generation effect requires active transformation not just storage]] — adds a time constraint to when generation must occur; processing after 24 hours generates from degraded context
- [[continuous small-batch processing eliminates review dread]] — complementary mechanism: this note addresses WHEN to process (urgency), that note addresses HOW OFTEN (continuous small batches prevent the accumulation that triggers dread)
- [[schema templates reduce cognitive overhead at capture time]] — the middle path between pure dumps and full processing: pre-defined fields enable faster capture than freeform while preserving more structure than raw dumps
- [[guided notes might outperform post-hoc structuring for high-volume capture]] — extends the middle path to streaming content: skeleton outlines may outperform post-hoc structuring when information flows faster than processing capacity
- [[Zeigarnik effect validates capture-first philosophy because open loops drain attention]] — complementary urgency at a shorter timescale: Ebbinghaus governs processing urgency (hours), Zeigarnik governs capture urgency (seconds); together they define the full temporal constraint on knowledge capture
- [[every knowledge domain shares a four-phase processing skeleton that diverges only in the process step]] — structural frame: temporal separation governs the gap between the skeleton's phase one (capture) and phase two (process); the Ebbinghaus constraint applies universally because the process step always requires contextual understanding regardless of domain

Topics:
- [[processing-workflows]]
