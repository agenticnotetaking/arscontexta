---
description: Templates constrain to deviation from fixed starting points while derivation traverses a claim graph to compose justified configurations, producing justification chains that improve recursively
kind: research
topics: ["[[design-dimensions]]"]
methodology: ["Original"]
source: [[knowledge-system-derivation-blueprint]]
---

# derivation generates knowledge systems from composable research claims not template customization

The tempting approach to producing knowledge systems for new use cases is to start with a template — a working system like this vault — strip the domain-specific parts, and offer what remains as a starting point. Users customize by removing what they don't need and adding what they want. This feels practical because templates provide immediate structure. But it fails at scale because the space of possible knowledge systems is vast, and templates can only cover the configurations their authors imagined.

Derivation works differently. Instead of starting with a fixed system and carving away, it starts with a graph of research claims about how knowledge systems work — since [[eight configuration dimensions parameterize the space of possible knowledge systems]], these claims span note design, linking philosophy, processing intensity, navigation structure, maintenance cadence, schema density, and automation level — and composes a new system by traversing relevant claims and making configuration decisions that each trace back to specific evidence. The output is not a simplified copy of an existing system but a novel configuration justified by the research that informs each choice.

Three properties make derivation fundamentally superior to templating. First, the configuration space is combinatorially large. Since [[knowledge system architecture is parameterized by platform capabilities not fixed by methodology]], the same conceptual system manifests differently depending on what the platform can support, and within each platform tier the eight configuration dimensions (granularity, organization, linking, processing intensity, navigation depth, maintenance cadence, schema density, automation level) interact to create millions of valid configurations. No template catalog covers this space because the combinations are multiplicative, not additive. Derivation can explore the space because it composes individual dimension choices rather than selecting from pre-composed packages — though since [[configuration dimensions interact so choices in one create pressure on others]], the valid region is far smaller than the raw combinatorial product, which actually helps by constraining derivation to coherent configurations.

This surface-level reshaping is why since [[schema fields should use domain-native vocabulary not abstract terminology]], vocabulary adaptation is the litmus test for genuine derivation — a template might rename folders and call itself "customized," but real derivation reshapes every linguistic surface to speak the target domain's language, because vocabulary carries the ontology the domain has developed through practice.

Second, derivation produces justification chains that templates cannot. When a derived system specifies atomic granularity with heavy processing and deep navigation, the justification chain explains why: atomic notes enable composability (research claim), composability requires explicit linking (interaction pressure), explicit linking demands processing capacity to maintain (constraint propagation), and deep navigation prevents the navigational vertigo that atomic systems create without local hierarchy (failure mode avoidance). Because [[methodology traditions are named points in a shared configuration space not competing paradigms]], derivation can reference these traditions as validated coherence points — Zettelkasten coheres at the atomic-explicit-deep-heavy end, PARA at the coarse-hierarchical-shallow-manual end — while composing novel combinations that no single tradition discovered. A template user gets the same configuration but not the reasoning. Without understanding why the system is shaped a certain way, the user cannot evolve it intelligently — they either drift from the template or preserve features they don't understand.

Third, derivation improves recursively. Since [[bootstrapping principle enables self-improving systems]], every system derived and deployed generates operational observations — what worked, what caused friction, what the users actually needed versus what the derivation predicted. Since [[evolution observations provide actionable signals for system adaptation]], these observations feed back into the claim graph through a diagnostic protocol that maps operational symptoms to structural causes, sharpening existing claims and generating new ones. The next derivation benefits from everything the previous ones learned. Templates improve too, but only through the template author's revisions. Derivation distributes the improvement across the entire claim graph, so discoveries in one deployment context improve derivations for all contexts.

But derivation has constraints that prevent it from being unconstrained generation. Since [[complex systems evolve from simple working systems]], Gall's Law requires that even a perfectly derived configuration start simple and evolve through use. The derivation process must target the minimum viable configuration for the user's platform and use case, then embed enough context for the system to evolve where friction emerges — and since [[context files function as agent operating systems through self-referential self-extension]], that context file is not just configuration but an operating system capable of teaching the agent how to extend the system it describes. A derivation that outputs a maximally complex system optimized for the user's stated needs violates evolutionary design even if every individual choice is research-justified. The right derivation produces a simple working system with a clear evolutionary path, not a complete system that needs no evolution.

The enabling condition for derivation is the claim graph itself — a dense, interlinked network where claims about note design connect to claims about linking strategy, which connect to claims about processing workflows, which connect to claims about maintenance cadence. Because [[dense interlinked research claims enable derivation while sparse references only enable templating]], this is not a quality preference but a structural threshold: four specific properties (atomic composability, dense interlinking, methodology provenance, semantic queryability) must be present before derivation can function at all. Since [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]], the derivation process is itself layered: foundation-layer choices (files, markdown, wiki links) are universal and require no user input, convention-layer choices (quality standards, naming patterns) depend on use case, automation-layer choices (hooks, skills, pipelines) depend on platform tier, and orchestration-layer choices (multi-phase processing, team coordination) depend on both platform tier and scale. Each layer narrows the audience while deepening the customization.

The relationship to existing parameterization work is complementary at multiple levels. Since [[knowledge system architecture is parameterized by platform capabilities not fixed by methodology]], parameterization describes what varies — the dimensions and their ranges. Derivation is the process of traversing those dimensions and composing specific values into a coherent system. And since [[composable knowledge architecture builds systems from independent toggleable modules not monolithic templates]], the composable architecture is the engineering pattern that makes derivation outputs implementable as independent toggles — derivation decides which dimension values to choose, composable architecture ensures those choices manifest as modules with explicit dependencies that can be adopted incrementally. Parameterization is the map of the space, derivation is the journey through it, and composable architecture is the vehicle that carries the chosen configuration to the agent as independently activatable modules rather than a monolithic package. All three are necessary: without parameterization, no decisions to make; without derivation, no principled way to make them; without composable architecture, no way to deliver them as incremental adoptions.

The practical value extends further: since [[every knowledge domain shares a four-phase processing skeleton that diverges only in the process step]], derivation for a new domain inherits capture, connect, and verify as structural constants, focusing design effort entirely on the process step — what transformation does this domain's content require? The pipeline structure is not derived but inherited, which simplifies derivation considerably. And since [[storage versus thinking distinction determines which tool patterns apply]], the generator must resolve an upstream classification before traversing configuration dimensions at all: a storage system and a thinking system occupy fundamentally different regions of the configuration space, making this the first decision that narrows the derivation search. When the target domain does not match any reference domain directly, the derivation agent needs an entry procedure — and since [[novel domains derive by mapping knowledge type to closest reference domain then adapting]], that entry procedure works by classifying what kind of knowledge the domain produces (factual, experiential, competency, outcome, social, creative), mapping to the reference domain that handles that type, then adapting temporal dynamics, ethical requirements, collaboration patterns, and retrieval needs. The analogy-based approach still produces justification chains because each mapping step — knowledge type classification, reference domain selection, adaptation rationale — is traceable and debatable.

Derivation also has a temporal dimension that extends beyond the initial generation event. Since [[derived systems follow a seed-evolve-reseed lifecycle]], the same claim graph that produces the initial derivation later enables principled re-derivation. During the evolution phase, a derived system accumulates observations about what works and what causes friction. When accumulated drift produces systemic incoherence — schemas that conflict, navigation that degrades, processing that no longer matches content — the system can be reseeded: re-derived using the original constraints enriched by accumulated operational evidence. This is where derivation's superiority over templating becomes most visible. A template-based system that has drifted can only be restructured by intuition, because the reasoning behind the original choices was never captured. A derived system retains its justification chains, and those chains combined with operational observations enable principled restructuring rather than ad hoc fixes.

The distribution problem is the final piece: derivation produces configuration choices, but those choices must reach the agent's platform in a form the agent can implement. Since [[blueprints that teach construction outperform downloads that provide pre-built code for platform-dependent modules]], the automation and orchestration layers cannot ship as pre-built artifacts because platform fragmentation makes any fixed implementation embed assumptions about where it runs. Derivation handles the intellectual problem of composing the right configuration; blueprints handle the distribution problem of getting that configuration implemented on each platform. Without blueprints, derivation would still produce monolithic downloads that resist cross-platform deployment — the intellectual work would be sound but the delivery would collapse back into the template distribution pattern that derivation was designed to replace.

The shadow side is that derivation quality depends entirely on claim graph quality. If the research claims are shallow, contradictory, or disconnected, the derived systems will be incoherent. This creates a chicken-and-egg problem: you need a good claim graph to derive good systems, but you need operational feedback from derived systems to build a good claim graph. The resolution is bootstrapping — start with the claims this vault has already validated through its own operation, derive initial systems, collect feedback, and iterate. The first derivations will be rough. The recursive improvement means they get better.

---
---

Relevant Notes:
- [[knowledge system architecture is parameterized by platform capabilities not fixed by methodology]] — provides the parameterization frame that derivation operates within: derivation decides configuration values, platform capabilities constrain which values are reachable
- [[bootstrapping principle enables self-improving systems]] — the recursive improvement loop that makes derivation compound: each derived system generates observations that feed back into the claim graph, making the next derivation better
- [[complex systems evolve from simple working systems]] — constrains derivation to produce minimum viable configurations rather than theoretically complete ones: Galls Law says even a perfectly derived system should start simple
- [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]] — derivation must respect the layer hierarchy: foundation choices are universal, orchestration choices are platform-specific, so the derivation process itself is layered
- [[eight configuration dimensions parameterize the space of possible knowledge systems]] — defines the specific dimensions derivation navigates: granularity, organization, linking, processing intensity, navigation depth, maintenance cadence, schema density, and automation level are the knobs the derivation agent turns
- [[configuration dimensions interact so choices in one create pressure on others]] — constrains derivation to produce coherent configurations: the valid configuration space is far smaller than the combinatorial product because dimension choices cascade, so derivation must satisfy interaction constraints not just individual dimension preferences
- [[methodology traditions are named points in a shared configuration space not competing paradigms]] — reframes what derivation has to work with: existing traditions are pre-validated coherence points in configuration space, so derivation can use them as seeds for novel combinations rather than starting from raw dimensions
- [[every knowledge domain shares a four-phase processing skeleton that diverges only in the process step]] — simplifies derivation for new domains: the pipeline structure is inherited rather than invented, with only the process step requiring domain-specific design
- [[storage versus thinking distinction determines which tool patterns apply]] — the upstream classification derivation must resolve first: before traversing configuration dimensions, the generator must identify whether the target system is storage or thinking, because the two types occupy fundamentally different regions of the configuration space
- [[context files function as agent operating systems through self-referential self-extension]] — identifies the output format that makes derived systems evolvable: the context file carries both methodology and self-extension instructions, so derivation produces not just a configuration but an operating system capable of adapting through use
- [[novel domains derive by mapping knowledge type to closest reference domain then adapting]] — the entry procedure when no reference domain matches directly: six knowledge type categories identify which reference domain's processing patterns transfer, then four adaptation dimensions customize the configuration
- [[schema fields should use domain-native vocabulary not abstract terminology]] — the linguistic adaptation constraint: derivation must reshape every surface label to speak the target domain's language, and this vocabulary adaptation is what distinguishes genuine derivation from template distribution wearing a different label
- [[multi-domain systems compose through separate templates and shared graph]] — the composition output: when derivation targets a use case spanning multiple knowledge types, it must compose separate domain templates within a shared graph, with five composition rules and domain coupling strength as the decision factor
- [[derived systems follow a seed-evolve-reseed lifecycle]] — temporal extension: derivation is not a one-time event but the mechanism that makes reseeding principled; the claim graph and justification chains enable re-derivation when accumulated evolution produces systemic incoherence
- [[evolution observations provide actionable signals for system adaptation]] — the feedback mechanism that makes recursive improvement concrete: six diagnostic patterns convert operational symptoms into specific structural corrections, testing whether derivation choices were correct
- [[premature complexity is the most common derivation failure mode]] — derivation's structural incentive toward thoroughness is both its strength and its primary risk: a richer claim graph produces more justified choices, but the composed system can be locally justified at every step while globally unsustainable, requiring a complexity budget as an external constraint
- [[configuration paralysis emerges when derivation surfaces too many decisions]] — the UX constraint on derivation: presenting every dimension as a question creates analysis paralysis; derivation must infer secondary choices from primary constraints and surface only genuine choice points, using justification chains to make defaults overrideable without requiring upfront comprehension
- [[blueprints that teach construction outperform downloads that provide pre-built code for platform-dependent modules]] — the distribution mechanism that completes derivation's output: derivation composes the right configuration choices, blueprints ship those choices to agents as construction instructions that adapt to each platform rather than pre-built code that embeds single-platform assumptions
- [[composable knowledge architecture builds systems from independent toggleable modules not monolithic templates]] — the engineering complement: derivation decides WHAT configuration to produce by traversing the claim graph, composable architecture decides HOW to implement that configuration as independently toggleable modules with explicit dependencies, making derivation outputs incrementally adoptable via addition rather than template subtraction
- [[dense interlinked research claims enable derivation while sparse references only enable templating]] — identifies the four structural prerequisites (atomic composability, dense interlinking, methodology provenance, semantic queryability) the research substrate must satisfy before derivation can function; expands the enabling condition into a full claim with a quality threshold below which agents fall back to templating

Topics:
- [[design-dimensions]]
