---
description: Operations producing identical results regardless of input content, context state, or reasoning quality belong in hooks; operations requiring semantic judgment each time belong in skills
kind: research
topics: ["[[agent-cognition]]", "[[processing-workflows]]"]
methodology: ["Original"]
source: [[hooks-as-methodology-encoders-research-source]]
---

# the determinism boundary separates hook methodology from skill methodology

Not all methodology belongs in the same place. The vault encodes its methodology across two complementary systems -- hooks and skills -- but the boundary between them is not arbitrary. The design principle is determinism: if an operation produces identical results regardless of input content, context window state, or agent reasoning quality, it belongs in a hook. If it requires semantic judgment that varies with each invocation, it belongs in a skill.

This distinction matters because conflating the two creates systems that are either brittle or unreliable. Since [[over-automation corrupts quality when hooks encode judgment rather than verification]], a hook that attempts connection finding would apply rules uniformly to a task that requires contextual judgment -- producing false positives, filling the graph with keyword-coincidence links, and degrading trust in the automation while metrics show healthy link density. A skill tasked with schema validation would waste reasoning budget on a check that should be a simple pattern match -- and worse, since [[hook enforcement guarantees quality while instruction enforcement merely suggests it]], leaving deterministic checks to skills means they only happen when the agent remembers to invoke them, which degrades as context fills.

The spectrum has three zones. At the deterministic end sit schema validation, dangerous command blocking, format enforcement, and auto-commit -- operations with clear pass/fail criteria that should fire identically on every invocation. In the middle sit workflow automations like index synchronization and context injection at session start, where the implementation involves complexity but the trigger logic remains deterministic: when this event fires, do this thing. At the far end sit intelligence operations -- connection finding, description quality evaluation, synthesis across domains -- which require the very capabilities hooks are designed to augment.

The crisp formulation: hooks encode the WHEN and the CHECK, while skills encode the HOW and the WHY. A hook can verify that a note has a description field. Only a skill can evaluate whether that description actually helps an agent decide whether to load the note. A hook can block a dangerous git command. Only a skill can judge whether a claim is specific enough to disagree with.

Since [[skills encode methodology so manual execution bypasses quality gates]], skills are the methodology itself in executable form. But hooks complement skills by handling the procedural substrate that skills should not waste reasoning on. Together they form the complete quality guarantee: hooks ensure deterministic checks happen on every operation without consuming context budget -- and since [[hooks enable context window efficiency by delegating deterministic checks to external processes]], the tokens saved redirect from procedural checking to cognitive work -- while skills ensure judgment-requiring operations get full cognitive attention. The result is that since [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]], the determinism boundary maps precisely onto the automation layer -- the point where methodology transitions from instruction-enforced suggestion to infrastructure-enforced guarantee.

The boundary is clear in most cases and fuzzy in a few. Staleness detection, for instance, could be a deterministic check (has this note been untouched for 30 days?) or a judgment call (is this note still accurate given recent additions?). Since [[programmable notes could enable property-triggered workflows]], property-triggered workflows push against the boundary by combining deterministic trigger conditions with potentially judgment-requiring actions. Even within the deterministic side, since [[nudge theory explains graduated hook enforcement as choice architecture for agents]], enforcement strength should vary -- blocking for structural failures, warning for quality degradation -- adding a second design dimension to the boundary question. And since [[confidence thresholds gate automated action between the mechanical and judgment zones]], the fuzzy cases need not remain a forced binary: where an automated system can score its own certainty, the three-tier response pattern (auto-apply above high confidence, suggest at medium confidence, log-only below) provides graduated resolution for operations that sit between the deterministic and semantic poles.

The safe default when the boundary is unclear is to err toward skills, because skills can reason about edge cases while hooks apply rules uniformly. Over-automation -- encoding judgment as rules -- is the more dangerous failure mode than under-automation, because a missed automatic check is visible while a wrong automatic decision corrupts silently. But even passing the determinism test is not sufficient for safe automation. Since [[idempotent maintenance operations are safe to automate because running them twice produces the same result as running them once]], a deterministic operation that appends a log entry on every event is deterministic -- same input always produces same output -- but running it twice produces a different result than running it once. Hooks fire on events, and events can repeat through crash recovery, overlapping timers, or redundant triggers. The determinism boundary asks "does this require judgment?" while the idempotency requirement asks "is this safe to repeat?" Both must pass for an operation to be safely hooked. This visibility asymmetry points to a complementary design axis: since [[automated detection is always safe because it only reads state while automated remediation risks content corruption]], the determinism question (does this require judgment?) and the read/write question (does this modify state?) are orthogonal constraints that both apply to automation decisions. A judgment-based detection like semantic duplicate matching is safe to automate despite crossing the determinism boundary because it only produces candidates for review. A deterministic remediation like auto-formatting is risky despite being fully deterministic if it modifies content meaning. And since [[methodology development should follow the trajectory from documentation to skill to hook as understanding hardens]], the boundary itself should be approached gradually: new methodology patterns start as instructions, harden into skills through use, and migrate to hooks only when the deterministic subset has been confirmed through accumulated experience. Patience prevents the premature encoding that makes over-automation tempting.

But since [[hooks cannot replace genuine cognitive engagement yet more automation is always tempting]], the boundary is not a fixed line but a frontier under constant pressure. What counts as "deterministic" expands as better heuristics emerge. Each expansion is individually justified -- why leave this to attention when infrastructure can guarantee it? -- but the cumulative effect could shrink the agent's cognitive role until thinking becomes form-filling. The boundary is a design choice, not a discovered truth, and maintaining it requires active resistance to the gravitational pull of automation.

---
---

Relevant Notes:
- [[skills encode methodology so manual execution bypasses quality gates]] -- the complementary claim about skill-encoded methodology; this note adds the hook side and defines where the boundary falls between them
- [[hook enforcement guarantees quality while instruction enforcement merely suggests it]] -- foundation: explains WHY hooks work (automatic enforcement), which is the mechanism that makes deterministic delegation viable
- [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]] -- the automation layer is precisely where this boundary operates, separating convention-layer instructions from hook-layer enforcement
- [[programmable notes could enable property-triggered workflows]] -- tests the boundary's edge cases: property-triggered workflows blur hook-like automation with skill-like semantic conditions
- [[over-automation corrupts quality when hooks encode judgment rather than verification]] -- develops the failure mode when the boundary is violated: keyword-matched links, automated categorization, and other judgment-as-rules produce invisible corruption that metrics cannot detect
- [[methodology development should follow the trajectory from documentation to skill to hook as understanding hardens]] -- adds the temporal dimension: this note defines WHERE the boundary falls, the trajectory note defines WHEN methodology should cross it as patterns become understood
- [[hooks enable context window efficiency by delegating deterministic checks to external processes]] -- quantifies the practical benefit of respecting the boundary: deterministic delegation saves thousands of tokens per session that redirect from procedural checking to cognitive work
- [[nudge theory explains graduated hook enforcement as choice architecture for agents]] -- refines the hook side: even within deterministic operations, enforcement strength should graduate from nudge to mandate based on violation severity, adding a second design dimension beyond the hook-vs-skill boundary
- [[hooks cannot replace genuine cognitive engagement yet more automation is always tempting]] -- the living tension: the determinism boundary is a design choice not a discovered truth, and evolutionary pressure always pushes it toward more automation as better heuristics expand what counts as deterministic
- [[automated detection is always safe because it only reads state while automated remediation risks content corruption]] -- complementary axis: this note separates operations by whether they require judgment (deterministic vs semantic), while the detection/remediation note separates by whether they read or write state; both boundaries constrain automation design but along different dimensions, and the read/write axis is arguably more fundamental because it determines blast radius rather than likelihood of errors
- [[confidence thresholds gate automated action between the mechanical and judgment zones]] -- extends this boundary from a binary into a three-zone spectrum: between fully deterministic hooks and fully semantic skills lies a confidence-gated zone where automation can act above a threshold and defer below it, operationalizing the fuzzy cases this note identifies as a graduated response pattern rather than a forced binary classification
- [[idempotent maintenance operations are safe to automate because running them twice produces the same result as running them once]] -- complementary second filter: this note asks whether the operation requires judgment, the idempotency note asks whether the operation is safe to repeat; both must pass for hook-level automation because hooks fire on events that inevitably recur

Topics:
- [[agent-cognition]]
- [[processing-workflows]]
