---
description: Granularity, organization, linking, processing intensity, navigation depth, maintenance cadence, schema density, and automation level — each a spectrum with poles, together defining what knobs a
kind: research
topics: ["[[design-dimensions]]"]
methodology: ["Original"]
source: [[knowledge-system-derivation-blueprint]]
---

# eight configuration dimensions parameterize the space of possible knowledge systems

The claim that knowledge systems are parameterized rather than fixed needs teeth. Saying "it depends on the use case" is vacuously true. What makes the design space tractable is identifying the specific dimensions along which systems vary and understanding what each dimension's poles actually trade off. Eight dimensions emerge from the research, and together they define the space a knowledge system generator navigates.

**Note granularity** ranges from atomic (one claim per note, as this vault practices) to coarse (one note per source, preserving original structure). Atomic granularity maximizes composability — since [[enforcing atomicity can create paralysis when ideas resist decomposition]], the cost is real, but atomic notes can be linked, rearranged, and synthesized independently in ways that compound notes cannot. Coarse granularity reduces capture friction and preserves source coherence, which matters when the primary operation is reference rather than synthesis. The right position depends on whether the system prioritizes retrieval of original context or generation of new connections.

**Organization** ranges from flat (all files in one directory, structure via wiki links) to hierarchical (nested folders with path-based navigation). Since [[associative ontologies beat hierarchical taxonomies because heterarchy adapts while hierarchy brittles]], flat organization accommodates evolving understanding because notes are not locked into categories at creation time. But hierarchical systems provide predictable locations for team collaboration and reduce navigational vertigo in large collections. Wiki link resolution constrains this choice — flat structures enable filename-only linking while hierarchical structures require path disambiguation.

**Linking philosophy** ranges from explicit only (every connection is manually created with articulated reasoning) to explicit plus implicit discovery (semantic search, embedding similarity, and algorithmic suggestions augment manual linking). Since [[propositional link semantics transform wiki links from associative to reasoned]], explicit-only linking produces higher-quality connections but scales poorly. Adding implicit discovery compensates for human or agent attention limits but introduces noise — because [[spreading activation models how agents should traverse]], the traversal mechanism must handle both curated and suggested edges without conflating their reliability.

**Processing intensity** ranges from heavy (extract, reflect, reweave, verify — the full pipeline this vault implements) to light (capture, route, review — minimal transformation). Since [[fresh context per task preserves quality better than chaining phases]], heavy processing produces higher-quality notes but demands more infrastructure and compute. Since [[every knowledge domain shares a four-phase processing skeleton that diverges only in the process step]], the intensity dimension specifically governs how much transformation happens in the process phase — capture, connect, and verify remain structural constants regardless of intensity level. Light processing suits domains where content arrives near-final (curated feeds, expert-written sources) or where the volume-to-value ratio is low enough that deep processing per item isn't justified.

**Navigation depth** ranges from two levels (hub linking directly to topic notes) to four levels (hub to domain to topic to sub-topic). Deeper navigation serves larger collections by providing intermediate orientation points, but each level adds maintenance burden and cognitive overhead during traversal. The right depth correlates with expected note count — a 50-note vault needs two levels, a 5000-note vault needs four — but also with the conceptual complexity of the domain. A domain with natural sub-structure (like "processing" splitting into capture, transformation, and retrieval) benefits from depth even at modest scale.

**Maintenance cadence** ranges from daily (a trading journal where yesterday's analysis becomes stale) to quarterly (a stable reference vault where core concepts change slowly). This dimension is often invisible in system design because maintenance happens — or fails to happen — as a social practice rather than an architectural feature. But cadence constrains other dimensions: daily maintenance requires lightweight review processes, while quarterly maintenance can afford deep reweaving passes. Domains with high temporal dynamics (markets, active research) need faster cadence than domains with slow conceptual evolution (mathematical foundations, historical analysis). Cadence also interacts with the governance rhythm: since [[organic emergence versus active curation creates a fundamental vault governance tension]], the cadence setting determines how frequently curation interventions occur, and setting cadence too high suppresses the emergence that generates organic structure while setting it too low lets structural debt accumulate past easy resolution.

**Schema density** ranges from minimal (description and topics only, roughly what any note needs to be findable) to dense (eight or more fields including methodology, classification, provenance, status, and custom domain fields). Dense schemas make notes queryable like a graph database — since [[faceted classification treats notes as multi-dimensional objects rather than folder contents]], each YAML field is an independent classification facet that composes multiplicatively for retrieval precision. But since [[storage versus thinking distinction determines which tool patterns apply]], the trade-off is real: each required field adds capture friction and maintenance burden. And since [[schema fields should use domain-native vocabulary not abstract terminology]], the density choice interacts with vocabulary: dense schemas amplify the cost of vocabulary mismatch because every abstractly-named field forces a translation step at capture time, so higher density demands more careful domain-native naming to remain usable. The right density depends on whether the primary access pattern is structured query (favoring dense) or free-form traversal (favoring minimal). Critically, since [[schema evolution follows observe-then-formalize not design-then-enforce]], the position on this spectrum should not be chosen upfront — systems should start minimal and move toward density only when usage evidence (manual field additions, patterned free text) justifies the cost of maintaining additional fields.

**Automation level** ranges from full (hooks enforce schemas on every write, skills encode methodology as executable workflows, pipelines coordinate multi-phase processing) to manual (all quality standards exist as written instructions that the agent follows by convention). Since [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]], automation level is partly determined by platform capability — you cannot automate what the platform does not support — and partly a design choice about system maturity. New systems benefit from starting manual (convention layer) and automating as understanding hardens, following the trajectory from documentation to skill to hook.

What makes these eight dimensions a useful parameterization rather than an arbitrary list is that they are largely independent in definition but interact in practice. A system positioned at "atomic granularity" does not logically require "heavy processing," but in practice, atomic notes need more connection work than coarse notes because the relationships lost by decomposing sources must be explicitly recreated. Since [[configuration dimensions interact so choices in one create pressure on others]], the space of viable configurations is much smaller than the combinatorial product of eight independent spectrums. This interaction structure also explains why [[methodology traditions are named points in a shared configuration space not competing paradigms]] — Zettelkasten, PARA, Cornell, and Evergreen each represent a coherent region where dimension interactions have been resolved through practice, not competing answers to the same question. The dimensions together define what a knowledge system generator decides when [[derivation generates knowledge systems from composable research claims not template customization]], while the universal components (notes, prose-as-title, wiki links, YAML base fields, graph mechanics, progressive disclosure) define what it never varies. But since [[dense interlinked research claims enable derivation while sparse references only enable templating]], the dimensions are only navigable when the claim graph supporting each dimension is dense enough — sparse research per dimension forces the derivation agent to guess rather than compose, degrading derivation to templating at the per-dimension level even if the overall graph appears large. And when a domain has no direct reference model, since [[novel domains derive by mapping knowledge type to closest reference domain then adapting]], knowledge type classification identifies which reference domain provides initial settings for these eight dimensions, with adaptation adjusting from that starting configuration rather than choosing each dimension from scratch.

---
---

Relevant Notes:
- [[knowledge system architecture is parameterized by platform capabilities not fixed by methodology]] — the upstream principle this concretizes: parameterization as concept needs specific dimensions to become actionable
- [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]] — layers describe WHERE features live while dimensions describe HOW features vary; the two are orthogonal decompositions of the same design space
- [[storage versus thinking distinction determines which tool patterns apply]] — the upstream classification before dimensions apply: a storage system and a thinking system occupy different regions of the eight-dimensional space
- [[enforcing atomicity can create paralysis when ideas resist decomposition]] — the failure mode at the atomic pole of the granularity dimension, grounding it in real trade-offs rather than abstract spectrum
- [[associative ontologies beat hierarchical taxonomies because heterarchy adapts while hierarchy brittles]] — the research case for one pole of the organization dimension
- [[propositional link semantics transform wiki links from associative to reasoned]] — moves along the linking philosophy dimension from implicit association toward explicit typed connections
- [[fresh context per task preserves quality better than chaining phases]] — grounds the heavy end of the processing intensity dimension in attention science
- [[configuration dimensions interact so choices in one create pressure on others]] — develops the interaction thesis: dimensions are independent in definition but coupled in practice, reducing the viable configuration space
- [[methodology traditions are named points in a shared configuration space not competing paradigms]] — extends: maps five major traditions as specific points in this eight-dimensional space, showing what instantiated dimension choices look like
- [[derivation generates knowledge systems from composable research claims not template customization]] — enables: derivation is the process that traverses these dimensions to compose justified configurations rather than selecting from templates
- [[every knowledge domain shares a four-phase processing skeleton that diverges only in the process step]] — constrains the processing intensity dimension by showing that capture, connect, and verify are structural constants while only the process step varies by domain
- [[faceted classification treats notes as multi-dimensional objects rather than folder contents]] — grounds the schema density dimension in Ranganathan's formal classification theory: each YAML field is an independent facet enabling multiplicative retrieval precision
- [[novel domains derive by mapping knowledge type to closest reference domain then adapting]] — operationalizes these dimensions for unfamiliar domains: knowledge type classification identifies which reference domain provides initial dimension settings, with adaptation adjusting from that starting configuration
- [[schema evolution follows observe-then-formalize not design-then-enforce]] — the temporal mechanism for the schema density dimension: rather than choosing density upfront, start minimal and let the five-signal quarterly review protocol move density in response to observed usage patterns
- [[schema fields should use domain-native vocabulary not abstract terminology]] — the naming constraint on the schema density dimension: dense schemas amplify vocabulary mismatch costs because every abstractly-named field forces a translation step, so higher density demands more careful domain-native naming
- [[organic emergence versus active curation creates a fundamental vault governance tension]] — the governance meta-dimension spanning maintenance cadence and automation level: cadence governs how frequently curation interventions occur, and automation level governs how much curation is delegated to infrastructure, with the governance rhythm determining the effective position on both spectrums
- [[configuration paralysis emerges when derivation surfaces too many decisions]] — the UX consequence of surfacing all eight dimensions: presenting every dimension as a question produces analysis paralysis; sensible defaults and inference from dimension coupling reduce the decision surface to genuine choice points
- [[premature complexity is the most common derivation failure mode]] — the deployment consequence of the combinatorial space: a derivation engine can justify choices along all eight dimensions, but the composed system exceeds user capacity, requiring a complexity budget that constrains initial deployment to a subset of these dimensions
- [[dense interlinked research claims enable derivation while sparse references only enable templating]] — the research quality prerequisite: dimensions are only navigable when each has dense, interlinked claims with methodology provenance; sparse coverage per dimension forces derivation to guess rather than compose, degrading to templating at the per-dimension level

Topics:
- [[design-dimensions]]
