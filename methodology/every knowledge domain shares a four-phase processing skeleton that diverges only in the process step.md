---
description: Capture, connect, and verify are domain-invariant operations while the process step (extract claims, detect patterns, build prerequisite maps, document decisions) carries all domain-specific logic
kind: research
topics: ["[[design-dimensions]]", "[[processing-workflows]]"]
methodology: ["PKM Research", "Systems Theory"]
source: [[knowledge-system-derivation-blueprint]]
---

# every knowledge domain shares a four-phase processing skeleton that diverges only in the process step

Across research synthesis, therapy journaling, project management, creative writing, personal life tracking, and relationship management, the same four operations recur in the same order: capture content, process it into domain-appropriate form, connect it to existing knowledge, then verify the result. The skeleton is universal. What makes a research vault different from a therapy journal is not the pipeline shape but what happens inside phase two.

This becomes visible when you lay domain processing side by side. Research extracts atomic claims from sources. Therapy detects patterns across temporal entries. Learning builds prerequisite maps and schedules reviews. Project management documents decisions with rationale. Personal life routes items to life areas and tracks goals. Relationships capture interaction details and surface follow-up patterns. Creative work develops ideas and links references to drafts. Each of these is a different process operation, but the surrounding phases — capture, connect, verify — are identical in function even when they differ in implementation detail. And since [[schema fields should use domain-native vocabulary not abstract terminology]], the names used for each phase should speak the domain's language — a therapy system calls its process step "pattern recognition" rather than "claim extraction," even though both occupy the same structural position in the skeleton. Because [[methodology traditions are named points in a shared configuration space not competing paradigms]], these domain variations are not competing approaches but different configurations of the same skeleton — each tradition chose its process step implementation based on what its domain requires.

The reason the skeleton holds is that capture, connection, and verification are structural operations while processing is semantic. Capture answers "what entered the system?" regardless of domain. Connection answers "what relates to what?" regardless of content type. Verification answers "is this well-formed and accurate?" regardless of subject matter. But processing answers "what does this content mean in domain terms?" — and meaning is inherently domain-specific. A therapy pattern recognition algorithm and a research claim extraction workflow share no logic even though they occupy the same structural position in their respective pipelines.

This has direct implications for system derivation. Since [[storage versus thinking distinction determines which tool patterns apply]], the skeleton operates in both system types but the process step carries the distinction: storage systems process by filing (classifying, routing, tagging), while thinking systems process by synthesizing (extracting claims, articulating connections, generating new understanding). In thinking systems, the process step is specifically the [[ThreadMode to DocumentMode transformation is the core value creation step]] — the act of transforming chronological captures into timeless claims. The skeleton itself is type-agnostic — even a pure storage system captures, processes, connects, and verifies. What differs is the cognitive intensity of phase two.

The vault's own pipeline demonstrates the skeleton concretely. Record (capture) → Reduce (process) → Reflect (connect) → Verify (verify) maps directly onto the four phases. The reduce phase is where domain-specific logic lives: mining for claims, detecting enrichment opportunities, classifying extraction types. The other phases are methodologically generic. Reflect finds connections regardless of what kind of content was processed — and because [[elaborative encoding is the quality gate for new notes]], the connect phase's value comes from articulated relationship reasoning rather than mechanical link-adding, a quality requirement that applies identically whether the processed content was research claims or therapy patterns. Verify checks quality regardless of domain semantics. This is why since [[fresh context per task preserves quality better than chaining phases]], phase isolation works so cleanly — the phases are genuinely different cognitive operations, not arbitrary divisions of continuous work.

Since [[throughput matters more than accumulation]], the skeleton also reveals where bottlenecks form. Capture is typically fast and getting faster (voice transcription, AI-assisted recording). Verification is automatable (schema checks, link validation). Connection-finding is computationally tractable (semantic search, graph traversal). Processing is the bottleneck because it requires domain expertise and semantic judgment. This matches the vault's experience: reduce is the most resource-intensive phase, the one where model quality matters most, the phase most likely to produce quality variation. The universal skeleton predicts that ANY knowledge system will find its bottleneck at the process step, because that is where domain complexity concentrates.

The shadow side is that "four phases" may be too clean. Real workflows involve feedback loops — verification failures that trigger reprocessing, connections that reveal the need for additional capture, processing that generates new items needing their own pipeline run. The skeleton describes the forward pass but not the backward maintenance that since [[structure without processing provides no value]] demands. The vault addresses this through reweaving — a backward pass that revisits old notes with new understanding — but reweaving does not fit neatly into the four-phase model. Since [[backward maintenance asks what would be different if written today]], reweaving is more like running the skeleton again with a different entry point: instead of starting from capture, you start from an existing note and ask what would be different if processed today. Whether this makes the skeleton a cycle rather than a sequence, or whether backward maintenance is genuinely a different operation, remains an open question worth investigating as more domain implementations emerge. And since [[derived systems follow a seed-evolve-reseed lifecycle]], the skeleton constrains what reseeding can restructure — the four phases themselves are invariant, so reseeding targets the process step implementation and the templates and navigation that sit on top of the skeleton, not the skeleton itself.

The skeleton's invariance also has a specific consequence for multi-domain systems. Since [[multi-domain systems compose through separate templates and shared graph]], the connect phase being domain-invariant is what makes cross-domain reflect possible. When a research insight about cognitive load needs to connect to a therapy reflection about stress patterns, the connection-finding operation is structurally identical regardless of which domain produced the content. Cross-domain reflect is not an extra feature bolted onto the skeleton — it is the natural consequence of having a domain-invariant connect phase operating over a shared graph. The cross-domain value that multi-domain composition promises depends directly on this structural constant.

The practical value for derivation is that since [[derivation generates knowledge systems from composable research claims not template customization]], when designing a knowledge system for a new domain you do not need to invent the pipeline from scratch. You inherit capture, connect, and verify as structural constants, then focus design effort entirely on the process step: what transformation does this domain's content require? But the skeleton's universality creates a seductive trap — because the shape transfers, it is tempting to assume the process step's content transfers too. Since [[false universalism applies same processing logic regardless of domain]], exporting a research vault's claim extraction to a therapy journal or a creative writing workspace produces systems that look well-structured but operate on the wrong transformation entirely. For unfamiliar domains where no reference processing pattern exists, the skeleton's invariance is what makes analogy-based derivation tractable — since [[novel domains derive by mapping knowledge type to closest reference domain then adapting]], the entire derivation challenge reduces to designing the right process step, and knowledge type classification (factual, experiential, competency, outcome, social, creative) identifies which existing process step implementation to start from. The skeleton's three constant phases mean the analogy only needs to transfer the process step, not the entire pipeline. Because [[configuration dimensions interact so choices in one create pressure on others]], the process step's intensity cascades through the rest of the skeleton — heavy processing demands dense linking in the connect phase and deeper navigation to remain traversable, while light processing allows the surrounding phases to stay minimal. Since [[eight configuration dimensions parameterize the space of possible knowledge systems]], the answer to that question combined with the dimension settings generates a complete pipeline specification.

---
---

Relevant Notes:
- [[storage versus thinking distinction determines which tool patterns apply]] — the storage/thinking split determines WHAT the process step produces: storage systems file, thinking systems synthesize, but both share the same four-phase skeleton
- [[throughput matters more than accumulation]] — throughput measures the velocity through the skeleton, not volume at any single phase; a system that captures fast but processes slow has a skeletal bottleneck
- [[fresh context per task preserves quality better than chaining phases]] — phase isolation is already the vault's implementation of this skeleton: each phase gets its own context because the operations are cognitively distinct
- [[structure without processing provides no value]] — the Lazy Cornell anti-pattern is precisely what happens when the skeleton runs with an empty process step: capture and connect without transformation produces organized noise
- [[eight configuration dimensions parameterize the space of possible knowledge systems]] — the skeleton constrains the processing intensity dimension specifically: capture, connect, and verify are constants, so intensity governs the process step's depth
- [[derivation generates knowledge systems from composable research claims not template customization]] — the skeleton is derivation's most actionable structural claim: inherit capture/connect/verify as constants, derive only the process step for new domains
- [[methodology traditions are named points in a shared configuration space not competing paradigms]] — traditions share the skeleton's shape and differ only in their process step implementations: Zettelkasten formulates, PARA summarizes, Cornell structures, GTD routes
- [[ThreadMode to DocumentMode transformation is the core value creation step]] — names what the process step does in thinking systems: the transformation from chronological ThreadMode captures into timeless DocumentMode claims is the skeleton's phase two
- [[configuration dimensions interact so choices in one create pressure on others]] — the process step's intensity cascades through the skeleton: heavy processing demands dense linking in the connect phase and deep navigation to remain traversable
- [[backward maintenance asks what would be different if written today]] — the backward pass that the skeleton's forward-only model cannot accommodate: reweaving re-enters the skeleton at the process step with existing notes rather than new captures
- [[elaborative encoding is the quality gate for new notes]] — grounds the connect phase in cognitive science: phase three's value depends on articulated relationship reasoning, not mechanical link-adding
- [[novel domains derive by mapping knowledge type to closest reference domain then adapting]] — operationalizes the skeleton for unfamiliar domains: knowledge type classification identifies which existing process step to start from, so the skeleton's invariance makes analogy-based derivation tractable
- [[schema fields should use domain-native vocabulary not abstract terminology]] — the vocabulary wrapping: the skeleton is universal but the names for each phase should speak the domain's language — a therapy system says 'pattern recognition' where this vault says 'claim extraction,' even though both occupy the same structural position
- [[multi-domain systems compose through separate templates and shared graph]] — cross-domain reflect exploits the skeleton's invariance: because the connect phase is domain-invariant, connection-finding across domain boundaries requires no additional infrastructure beyond the shared graph
- [[derived systems follow a seed-evolve-reseed lifecycle]] — the skeleton constrains what reseeding restructures: the four phases are invariant, so reseeding targets the process step implementation and surrounding templates rather than the pipeline shape itself
- [[false universalism applies same processing logic regardless of domain]] — the trap this skeleton's universality creates: because the four-phase shape holds everywhere, it is tempting to export the process step's content unchanged — but the skeleton's invariance is structural, not operational, and confusing the two produces technically executable but semantically empty systems
- [[maintenance operations are more universal than creative pipelines because structural health is domain-invariant]] — extends the skeleton's invariance insight to the backward pass: the operations that maintain the skeleton's health (schema validation, orphan detection, link integrity) are even more transferable than the skeleton's forward phases because they check structural properties entirely, clustering in lower abstraction layers and requiring less platform infrastructure

Topics:
- [[design-dimensions]]
- [[processing-workflows]]
