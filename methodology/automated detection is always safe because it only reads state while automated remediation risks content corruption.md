---
description: The read/write asymmetry in automation safety means detection at any confidence level produces at worst a false alert, while remediation at insufficient confidence produces changes harder to fix than
kind: research
topics: ["[[maintenance-patterns]]", "[[agent-cognition]]"]
methodology: ["Original"]
source: [[automated-knowledge-maintenance-research-source]]
---

# automated detection is always safe because it only reads state while automated remediation risks content corruption

The most important design principle for automated knowledge maintenance is not whether an operation requires judgment but whether it reads or writes. This is a different axis from [[the determinism boundary separates hook methodology from skill methodology]], which asks whether the operation's correctness can be determined without contextual reasoning. Both axes matter, but the read/write asymmetry is more fundamental because it determines the blast radius of errors rather than their likelihood.

Consider what happens when detection gets something wrong. An orphan detection script flags a note that actually has incoming links from a file it missed. A staleness detector identifies a note as outdated when it was deliberately written in timeless terms. A schema validator reports a missing field that the template has since made optional. In every case, the worst outcome is a false alert — the agent or human examines the flag, determines it is incorrect, and ignores it. No content was modified. No links were corrupted. No notes were silently degraded. The false positive consumed attention but caused no damage. This is why detection can be maximally aggressive: the failure mode is bounded, and since [[maintenance scheduling frequency should match consequence speed not detection capability]], the only constraint on detection frequency is how fast the problem propagates, not the risk of running the check. Even judgment-based detection — like semantic duplicate candidate identification through vector similarity — is safe to automate because it produces candidates for review, never modifications to files.

Now consider what happens when remediation gets something wrong. An automated link-adder connects notes that share vocabulary but not meaning. An auto-archiver moves a note the human was actively developing. A description rewriter replaces a nuanced phrasing with a generic summary. In every case, the outcome is content corruption — changes that are harder to fix than the original problem because the incorrect state looks valid. Since [[over-automation corrupts quality when hooks encode judgment rather than verification]], the keyword-matched link is a paradigmatic example: the link exists, points to a real note, and structurally looks identical to a genuine connection. Nothing in the system flags it as wrong because nothing can distinguish it from a real link without re-performing the judgment that should have been done correctly in the first place.

The asymmetry runs deeper than false positive rates. Detection errors are self-correcting because they present themselves for evaluation. Every detection result, whether correct or incorrect, passes through a decision point where judgment can filter it. Remediation errors are self-concealing because they modify the state that subsequent detection operates on. A wrong link, once added, becomes part of the graph topology that future connection-finding traverses. A wrong archive, once executed, removes the note from the working set that future maintenance scans. The error does not surface for review because the system now treats the corrupted state as the ground truth. This is also why [[reconciliation loops that compare desired state to actual state enable drift correction without continuous monitoring]] structurally separate their detection phase (comparing desired state to actual state) from their remediation phase (correcting the drift) — the detection comparison is always safe to schedule because it only reads, while the correction actions range from fully automated to judgment-requiring depending on the operation.

This is why every mature automation system converges on the same architecture. Wikipedia's ClueBot NG can process 1.5 million edits per day because its detection is aggressive — pattern matching against known vandalism signatures, computing edit distance metrics, flagging anomalous patterns — while its remediation is conservative: revert only when confidence exceeds a high threshold, escalate ambiguous cases to human review. CI/CD pipelines run comprehensive test suites (detection) on every commit but require human approval for production deployments (remediation). The SRE practice of detect-aggressively-remediate-conservatively is not a preference but a structural response to this asymmetry.

For agent-operated knowledge systems, the principle translates directly. Since [[hook enforcement guarantees quality while instruction enforcement merely suggests it]], detection hooks are the safest automation investment because they combine the reliability of hook enforcement with the bounded failure mode of read-only operations. A hook that checks schema compliance on every write detects violations with zero risk of content corruption. A hook that auto-fixes schema violations by guessing default values would write incorrect content with the same reliability. Since [[schema validation hooks externalize inhibitory control that degrades under cognitive load]], schema validation works so well precisely because it occupies the intersection of deterministic AND read-only — but the read-only property is doing more work than the determinism property. A non-deterministic detection (like fuzzy duplicate matching) is still safe because it only flags. A deterministic remediation (like auto-formatting whitespace) is still risky if it modifies content in ways that change meaning. The safety of read-only detection extends further: since [[idempotent maintenance operations are safe to automate because running them twice produces the same result as running them once]], detection is trivially idempotent — running orphan detection ten times produces the same alert list as running it once — while remediation operations need explicit idempotency guards (compare-before-acting, upsert semantics, unique identifiers) to prevent repeated execution from compounding errors.

The practical design rule: automate detection to the maximum extent possible regardless of confidence level, because false alerts are cheap and correctable. Since [[confidence thresholds gate automated action between the mechanical and judgment zones]], remediation should be gated behind confidence thresholds that increase with the irreversibility of the change. A remediation that adds a wiki link (easily removed) can tolerate lower confidence than one that rewrites a description (harder to recover the original phrasing) or archives a note (may be lost from working memory even if technically recoverable). The confidence threshold is not about whether the detection was accurate but about whether the remediation is reversible.

This also explains why the vault's pipeline architecture separates detection from action through human or agent decision points. The /review skill detects problems and logs them as tension notes — detection with zero remediation. The /reweave skill performs both detection and remediation but does so through agent judgment in a fresh context window, never through automated rules. The separation is not incidental but structural: it preserves the asymmetry that makes detection safe and prevents remediation from running without the judgment that its write operations demand.

---
---

Relevant Notes:
- [[the determinism boundary separates hook methodology from skill methodology]] — complementary axis: determinism separates hook from skill by whether the operation requires judgment, while this note separates detection from remediation by whether the operation reads or writes state; both boundaries constrain automation design but along different dimensions
- [[over-automation corrupts quality when hooks encode judgment rather than verification]] — develops the remediation failure mode: keyword-matched links are automated remediation that corrupts because the writing was wrong, not because the detection was wrong; the corruption is invisible precisely because the system wrote something plausible
- [[hook enforcement guarantees quality while instruction enforcement merely suggests it]] — detection hooks inherit the full enforcement guarantee because they only read and report, making them safe candidates for the most aggressive automation possible
- [[schema validation hooks externalize inhibitory control that degrades under cognitive load]] — paradigmatic safe automation: schema validation is both deterministic AND read-only detection, which is why it works so well as a hook; this note explains why detection safety is the more fundamental property
- [[confidence thresholds gate automated action between the mechanical and judgment zones]] — operationalizes the remediation side: this note establishes that remediation needs gating, the confidence thresholds note specifies the three-tier response pattern (auto-apply, suggest, log-only) that calibrates how aggressively remediation acts based on measured certainty
- [[idempotent maintenance operations are safe to automate because running them twice produces the same result as running them once]] — complementary safety dimension: the read/write axis determines blast radius of errors while idempotency determines whether repeated execution compounds errors; read-only detection is trivially idempotent, but write operations need explicit idempotency guards even when the detection that triggered them was correct
- [[reconciliation loops that compare desired state to actual state enable drift correction without continuous monitoring]] — architectural embodiment: reconciliation loops structurally separate detection (compare desired to actual) from remediation (correct drift), implementing the asymmetry this note describes as a scheduling pattern where detection runs freely while remediation gates behind judgment
- [[maintenance scheduling frequency should match consequence speed not detection capability]] — extends the detection aggressiveness principle: since detection is always safe, the constraint on detection frequency is not risk but consequence speed; instant-consequence problems justify per-event detection hooks while slow-consequence problems justify periodic checks, but both are safe to schedule aggressively because detection only reads state

Topics:
- [[maintenance-patterns]]
- [[agent-cognition]]
