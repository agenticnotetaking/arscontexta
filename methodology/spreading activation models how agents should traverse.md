---
description: Memory retrieval in brains works through spreading activation where neighbors prime each other. Wiki link traversal replicates this, making backlinks function as primes that surface relevant contexts
kind: research
topics: ["[[agent-cognition]]"]
---

# spreading activation models how agents should traverse

## The Activation Model

Graph traversal IS spreading activation. When you follow wiki links to load context, you're replicating what the brain does when priming related concepts. The activation spreads from the starting node through connected nodes, decaying with distance. Since [[wiki links implement GraphRAG without the infrastructure]], every link you traverse is a curated edge, not a statistical correlation, which means the activation spreads through high-signal paths.

This isn't just analogy — it's the same computational pattern. Discovery layers (file tree → descriptions → outline → section → full content) implement spreading activation in practice. Each step loads more context with higher cost. High decay traversal stops at the description. Low decay traversal reads full files. The progressive disclosure framework IS decay-based context loading. Since [[structure enables navigation without reading everything]], these four structural mechanisms — wiki links, MOCs, claim titles, and YAML descriptions — compose into the discovery layer stack that makes this decay-based traversal possible in the first place.

Since [[descriptions are retrieval filters not summaries]], the description layer serves a specific function: enabling agents to decide whether to load full content. This maps to information-theoretic filtering — lossy compression that preserves decision-relevant features. The description answers "should I read this?" not "what does this say?" Since [[metadata reduces entropy enabling precision over recall]], aggregating descriptions creates a pre-computed low-entropy representation that shrinks the search space before content loads, enabling efficient high-decay traversal.

Cognitive science mapped how memory retrieval works: activate a concept, neighboring concepts receive activation proportional to connection strength, activation decays with each hop. The key insight for agents: backlinks function as primes. When you visit a note, its backlinks show every context where this concept was previously useful. Since [[backlinks implicitly define notes by revealing usage context]], the backlinks don't just show WHERE a concept was used — they reveal WHAT the concept means in practice, extending its definition beyond the author's original intent. Since [[wiki links implement GraphRAG without the infrastructure]], notes function as APIs — the title is the function signature, the body is the implementation, and following a link is a function call. Each API invocation spreads activation to the referenced concept. And because [[inline links carry richer relationship data than metadata fields]], the prose surrounding each link encodes the relationship TYPE — "since X, therefore Y" carries more activation signal than a bare reference. The link type annotation tells the traverser whether to follow: a causal connection warrants deeper traversal than a mere association.

This aligns with distributed cognition theory: cognition is not confined to the brain but extends into tools and environments. A vault with wiki links acts as an exocortex, holding associative pathways that any agent (biological or artificial) can traverse. Following links IS spreading activation through an external thinking structure. And because [[knowledge systems become communication partners through complexity and memory humans cannot sustain]], this traversal isn't just retrieval — it's dialogue with a system that holds complexity the agent couldn't sustain alone. The vault surprises its operators by surfacing connections they made but forgot, which means spreading activation isn't just loading context but communicating with an external partner. And since [[AI shifts knowledge systems from externalizing memory to externalizing attention]], spreading activation is better understood as an attention allocation mechanism than a memory retrieval one. The decay parameter does not decide what to remember — it decides what to attend to. High decay focuses attention narrowly; low decay spreads attention broadly. The system is not recalling stored knowledge so much as directing finite attention through the graph, deciding which nodes deserve the agent's limited cognitive bandwidth.

## Implementation Parameters

Traversal requires tuning:
- **Decay rate**: how quickly activation fades per hop (high decay = focused retrieval, low decay = exploratory)
- **Threshold**: minimum activation to follow a link (prevents traversing everything)
- **Max depth**: hard limit on traversal distance — since [[LLM attention degrades as context fills]], depth limits aren't just about token counts but about where the "smart zone" ends

The insight changes how agents should navigate. Focused retrieval (answering a specific question) wants high decay — go deep on the most relevant path. Exploratory synthesis (finding connections) wants low decay — spread wider to discover non-obvious relationships. Both modes serve the same underlying principle: since [[retrieval utility should drive design over capture completeness]], the traversal mechanism exists to answer "how do I find what I need?" not "where did I file this?" The exploratory mode is where [[controlled disorder engineers serendipity through semantic rather than topical linking]] — low-decay traversal through semantic cross-links encounters unexpected neighbors that topical filing would segregate, and these surprises are precisely the discovery mechanism that Luhmann identified as the source of productive insight. The agent following a link from "context window constraints" to "spaced repetition scheduling" didn't search for that connection — the graph's semantic linking surfaced it because the connecting link passed a judgment test even though the topics diverge.

But decay and threshold only address WHICH nodes to visit next. They don't address when the search itself should change direction. Since [[queries evolve during search so agents should checkpoint]], agents need explicit reassessment points during traversal. The berrypicking model shows that understanding what you're looking for changes as you find things. Spreading activation says follow strong links with decay. Checkpointing says pause periodically to ask: am I still looking for the right thing?

## Integration with Traversal Architecture

Together with the other foundational claims, this forms a complete traversal architecture. Wiki links provide the graph structure (WHAT to traverse). Spreading activation provides the loading mechanism (HOW to traverse). Small-world topology provides the efficiency guarantees (WHY the structure works). Checkpointing provides the reassessment protocol (WHEN to change direction). Each pillar answers a different question about agent cognition.

But spreading activation operates on an existing graph — it discovers connections that wiki links have already encoded. The question is whether some connections only become visible during the extraction process itself, before links exist. Since [[incremental reading enables cross-source connection finding]], forced context collision during interleaved processing may surface relationships that sequential extraction followed by spreading-activation-based reflect would miss. Spreading activation is powerful once the graph exists; incremental reading proposes that graph construction itself could be serendipity-generating.

Since [[dual-coding with visual elements could enhance agent traversal]], there may be a parallel activation network operating through visual representations rather than textual links. If Mermaid diagrams or relationship graphs activate related concepts through spatial proximity and visual grouping, this would provide modal redundancy: when the textual path fails (agent doesn't recognize a connection), the visual path might succeed. This remains a research direction rather than validated architecture.

This also explains why MOCs work as navigation hubs. They're high-activation nodes that prime many related concepts simultaneously. Starting from a MOC spreads activation across an entire topic area, which is exactly what you want when exploring unfamiliar territory. But activation alone cannot tell you which starting node to activate first or which activation pattern proved productive in prior sessions — this is where [[agent notes externalize navigation intuition that search cannot discover and traversal cannot reconstruct]], capturing the strategic layer (start here, combine these, skip that) that guides activation before it begins spreading.

The efficiency of spreading activation depends on network structure. Because [[small-world topology requires hubs and dense local links]], most concept pairs connect through surprisingly few hops. High clustering creates local coherence (related concepts near each other), while hub nodes (MOCs) create shortcuts across the network. This topology ensures spreading activation reaches relevant nodes quickly without flooding the context window. And because [[betweenness centrality identifies bridge notes connecting disparate knowledge domains]], we can quantify which specific nodes activation preferentially flows through — high-betweenness nodes are the natural waypoints that agents encounter repeatedly during diverse traversals, regardless of starting point.

A further refinement comes from research on memory-augmented agents. BudgetMem introduces a trained neural router that dynamically selects extraction depth based on query characteristics — not all retrievals deserve the same traversal investment. The router learns three tiering strategies: shallow extraction for simple lookups, medium for contextual queries, and deep for synthesis tasks. This suggests that the decay parameter in spreading activation should not be fixed but query-dependent: the same graph traversed for a factual check (high decay, shallow) versus a synthesis search (low decay, deep) should use different activation profiles. The vault's current implementation approximates this through skill-specific search mode selection (BM25 for /seed, vsearch for /reduce, full query for /reflect), but a learned router could optimize this further as the graph scales.

But spreading activation has a blind spot. Since [[navigational vertigo emerges in pure association systems without local hierarchy]], activation can only spread through existing links. Semantic neighbors that lack explicit connections remain invisible — they're close in meaning but distant (or unreachable) in graph space. This is why MOCs matter not just for efficiency but for completeness: they provide local hierarchy that surfaces content spreading activation alone would miss.
---

Relevant Notes:
- [[progressive disclosure means reading right not reading less]] — applies spreading activation to argue that disclosure layers enable curation for quality, not efficiency for token savings
- [[structure enables navigation without reading everything]] — synthesis: composes the four structural mechanisms (wiki links, MOCs, claim titles, descriptions) into the discovery layer stack that spreading activation traverses; the structural substrate that makes decay-based context loading operational
- [[wiki links implement GraphRAG without the infrastructure]] — provides the graph structure; also develops the notes as APIs metaphor where link traversal is function invocation
- [[inline links carry richer relationship data than metadata fields]] — extends the API metaphor: inline links are TYPED function calls where prose provides the type annotation that guides traversal decisions
- [[backlinks implicitly define notes by revealing usage context]] — explains WHY backlinks function as primes: they reveal not just where a concept was used but what it means in practice across the graph
- [[small-world topology requires hubs and dense local links]] — explains the structural basis for why few hops suffice
- [[queries evolve during search so agents should checkpoint]] — adds the temporal dimension: when to reassess search direction during traversal
- [[dangling links reveal which notes want to exist]] — shows how high-frequency placeholder links predict which notes will enter the graph as high-activation hubs
- [[processing effort should follow retrieval demand]] — traversal frequency creates the demand signal that determines where processing investment should flow
- [[descriptions are retrieval filters not summaries]] — explains the information-theoretic basis for why descriptions enable high-decay traversal: lossy compression preserving decision-relevant features
- [[good descriptions layer heuristic then mechanism then implication]] — operationalizes decay levels within descriptions: high-decay stops at heuristic, medium at mechanism, low at implication
- [[throughput matters more than accumulation]] — traversal frequency reveals what actually gets used, providing objective throughput metrics
- [[each new note compounds value by creating traversal paths]] — explains what spreading activation moves through: compounding creates the path network, this note explains how to traverse it
- [[LLM attention degrades as context fills]] — grounds the max depth parameter: depth limits not because of tokens but because attention quality degrades beyond the smart zone
- [[trails transform ephemeral navigation into persistent artifacts]] — proposes caching successful activation paths across sessions as named trails
- [[maintenance targeting should prioritize mechanism and theory notes]] — applies spreading activation to reweave: for experiments, mechanism connection should guide where activation spreads rather than topic proximity
- [[retrieval utility should drive design over capture completeness]] — the design orientation spreading activation serves: traversal answers how do I find this not where did I file it
- [[dual-coding with visual elements could enhance agent traversal]] — proposes visual representations as a parallel activation network operating alongside textual wiki links
- [[incremental reading enables cross-source connection finding]] — addresses discovery at a different stage: spreading activation traverses existing connections; incremental reading discovers connections during extraction, before links exist
- [[mnemonic medium embeds verification into navigation]] — proposes using link context phrases as verification prompts that activation encounters during traversal, making verification ambient rather than a separate phase
- [[knowledge systems become communication partners through complexity and memory humans cannot sustain]] — the partnership thesis: traversal isn't just retrieval but dialogue with a system that holds complexity agents couldn't sustain alone
- [[navigational vertigo emerges in pure association systems without local hierarchy]] — the blind spot: activation only spreads through existing links, so semantic neighbors without link paths remain invisible regardless of decay tuning
- [[notes function as cognitive anchors that stabilize attention during complex tasks]] — explains WHY traversal through notes stabilizes reasoning: each note is an anchor that prevents mental model collapse, so link-following is not just information loading but cognitive stabilization
- [[AI shifts knowledge systems from externalizing memory to externalizing attention]] — reframes: spreading activation is better understood as attention allocation than memory retrieval; decay parameters decide what to attend to, not what to remember
- [[betweenness centrality identifies bridge notes connecting disparate knowledge domains]] — quantifies which nodes activation preferentially flows through: high-betweenness nodes sit on the most shortest paths, making them natural waypoints that agents encounter repeatedly during diverse traversals
- [[controlled disorder engineers serendipity through semantic rather than topical linking]] — explains what low-decay exploratory traversal encounters: semantic cross-links create unexpected neighbors that topical filing would segregate, and these surprising adjacencies are the discovery mechanism that makes exploratory mode productive
- [[agent notes externalize navigation intuition that search cannot discover and traversal cannot reconstruct]] — the strategic layer above activation: spreading activation determines which nodes to visit next, but agent notes capture which starting points and activation patterns proved productive in prior sessions, providing meta-guidance that the mechanism itself cannot generate

Topics:
- [[agent-cognition]]
