---
description: Larson & Czerwinski (1998) found deeper hierarchies outperform flat ones only when labels enable confident branch commitment — context phrases provide that clarity in MOC hierarchies
kind: research
topics: ["[[graph-structure]]"]
methodology: ["Cognitive Science", "PKM Research"]
source: [[2026-02-08-moc-architecture-hierarchy-blueprint]]
---

# context phrase clarity determines how deep a navigation hierarchy can scale

Hierarchical navigation has two independent scaling dimensions: how many items per level (breadth) and how many levels deep (depth). Breadth scaling is well understood — since [[basic level categorization determines optimal MOC granularity]], Rosch's prototype theory predicts that MOC titles work best at the "chair" level, specific enough to orient but general enough to cluster. But depth scaling follows a different logic, and the critical variable is label quality, not content volume.

Larson and Czerwinski (1998) established this through navigation performance experiments: structures with roughly eight items per level and two to three levels consistently produce optimal results, but only under a crucial condition. When category labels are clear, deeper hierarchies outperform flat ones because navigators commit to the correct branch with confidence. They read the label, understand the scope, and descend without anxiety. When labels are ambiguous, flatter structures win because navigators need to scan more options before committing — premature descent into the wrong branch costs more than breadth scanning.

This translates directly to MOC architecture. The "labels" in a MOC are context phrases — the brief explanations after each wiki link that articulate why a note matters for this topic. A bare link list is maximally ambiguous: the title tells you what the note claims but nothing about why it belongs here or what role it plays. Since [[descriptions are retrieval filters not summaries]], the same principle operates at the note level — descriptions that merely paraphrase fail as filters. Context phrases that merely restate the title ("related to graph structure") fail as navigation aids. In both cases, the compression needs to add information that enables a decision, not echo information already visible. The cognitive mechanism behind this is specific: since [[elaborative encoding is the quality gate for new notes]], writing a context phrase that articulates why a note belongs in a particular MOC section requires processing the relationship between that note and the MOC's theme — and that processing is what produces the label clarity that Larson and Czerwinski found necessary for confident branch commitment. A bare link skips the elaboration entirely, which is why it fails as a navigation aid.

The depth-scaling consequence is significant. A MOC with clear context phrases — "structural requirement: the topology that makes traversal efficient" rather than just linking to the note — can sustain more entries per section and more tiers in the hierarchy because each navigation decision is well-informed. Because [[inline links carry richer relationship data than metadata fields]], the quality of these context phrases concentrates at hubs — MOCs are high-traffic nodes where many traversals pass through, so the relationship context in MOC links determines navigation quality across the entire network. The hub effect means that clarity at MOC level has outsized impact: improving context phrases in a single MOC improves every traversal that passes through it. The agent reads the context phrase, evaluates relevance to the current task, and either follows the link or moves on. The decision cost per entry stays low even as the MOC grows because the phrase front-loads the reasoning. But a bare link list hits navigation ceiling quickly. Without context phrases, the agent must either load each linked note to evaluate relevance (expensive) or guess from the title alone (error-prone). At two tiers deep with eight items per level, that's potentially sixty-four leaf nodes where every wrong-branch commitment wastes a full descent before backtracking.

This is why since [[stale navigation actively misleads because agents trust curated maps completely]], the clarity requirement is especially acute for agents. Humans retain cross-session intuition that might override an ambiguous label — "I think that section covers retrieval, not capture." Agents have no such fallback. They read the context phrase, take it as ground truth, and navigate accordingly. An ambiguous phrase doesn't trigger broader scanning; it triggers confident but potentially wrong commitment. The trust that makes curated navigation valuable is the same trust that makes ambiguous navigation dangerous.

The practical implication connects depth-scaling to maintenance investment. Since [[progressive disclosure means reading right not reading less]], context phrases function as a disclosure layer within MOCs themselves. Each phrase is a micro-decision point: "is this branch worth descending into?" The quality of these micro-decisions determines whether a three-tier hierarchy (hub to domain to topic to claims) functions as efficient progressive disclosure or as a maze of uncertain branch points. Since [[structure enables navigation without reading everything]], the four structural mechanisms compose into a navigation system — but how deep that system can layer before performance degrades depends directly on the clarity of the labels at each junction.

This clarity does not arise automatically. Since [[MOC construction forces synthesis that automated generation from metadata cannot replicate]], the Dump-Lump-Jump pattern reveals that the synthesis work of the Jump phase — identifying tensions, writing orientation, seeing the collection as a whole — is precisely what produces quality context phrases. Automated MOC generation can match notes to topics but cannot perform the elaborative processing that creates the label clarity depth-scaling requires. The practical consequence is that context phrase quality is a maintenance investment, not a one-time cost: every MOC update that adds a note with a thoughtful context phrase extends the depth the hierarchy can sustain, while every bare-link addition erodes it. And since [[MOC maintenance investment compounds because orientation savings multiply across every future session]], this is not merely a cost to bear but an investment with compound temporal returns — each phrase refined today improves navigation in every future session that loads the MOC, making the depth-scaling benefit permanent rather than ephemeral.

The relationship between breadth and depth scaling creates an architectural trade-off. Rosch's basic level theory constrains breadth (MOC titles at the right granularity), while Larson and Czerwinski constrain depth (label clarity enabling confident descent). Together they predict that a well-designed MOC hierarchy has basic-level titles at each tier AND clear context phrases at each link — and that violating either constraint produces distinct failure modes. Wrong granularity makes individual MOCs hard to use. Unclear phrases make the tier structure hard to navigate. Both failures look different but share a root cause: the agent cannot make confident navigation decisions from the information available at the decision point.

---
---

Relevant Notes:
- [[structure enables navigation without reading everything]] — foundation: develops the four structural mechanisms; this note adds the depth-scaling dimension that determines how far those mechanisms can layer
- [[basic level categorization determines optimal MOC granularity]] — complementary scaling dimension: Rosch predicts optimal breadth (what granularity to target), Larson & Czerwinski predict optimal depth (how many tiers the hierarchy can sustain); both are needed for MOC architecture
- [[navigational vertigo emerges in pure association systems without local hierarchy]] — the failure mode that hierarchy prevents, but only when labels enable confident navigation; ambiguous labels at each tier compound vertigo rather than resolving it
- [[descriptions are retrieval filters not summaries]] — parallel mechanism at the note level: descriptions filter individual notes the way context phrases filter MOC entries; both are lossy compression optimized for decision-making rather than summarization
- [[stale navigation actively misleads because agents trust curated maps completely]] — the trust that makes clarity critical: agents don't second-guess MOC entries, so an unclear context phrase doesn't prompt exploration — it prompts wrong-branch commitment
- [[progressive disclosure means reading right not reading less]] — context phrases are a disclosure layer within MOCs: they let agents decide which branch to follow without loading every linked note
- [[elaborative encoding is the quality gate for new notes]] — cognitive mechanism: writing clear context phrases IS elaborative encoding at the MOC level; the depth of processing required to articulate why a note belongs here is what produces the label clarity that enables confident branch commitment
- [[MOC construction forces synthesis that automated generation from metadata cannot replicate]] — production mechanism: the Dump-Lump-Jump pattern explains how context phrase clarity gets produced; automated generation skips the Jump-phase synthesis that creates the label quality this note identifies as the depth-scaling constraint
- [[inline links carry richer relationship data than metadata fields]] — extends: context phrases are the MOC-level instance of the hub effect; since typed inline links at hubs determine navigation quality across the network, the clarity requirement compounds at every tier of the hierarchy
- [[navigation infrastructure passes through distinct scaling regimes that require qualitative strategy shifts]] — temporal frame: scaling regimes define WHEN deeper hierarchies become necessary (Regime 2+); this note defines WHAT enables them (label clarity enabling confident descent)
- [[eight configuration dimensions parameterize the space of possible knowledge systems]] — constrains the navigation depth dimension: the eight-dimensions note parameterizes depth as a design choice, while this note specifies the quality prerequisite that determines how far depth can extend before navigation performance degrades
- [[complete navigation requires four complementary types that no single mechanism provides]] — sibling: context phrases serve the local navigation type specifically; the four-type framework explains why local navigation needs its own quality mechanism (depth-enabling labels) independent of how well global, contextual, or supplemental types function
- [[MOC maintenance investment compounds because orientation savings multiply across every future session]] — sibling: context phrase quality is not a one-time cost but an investment with compound temporal returns; each phrase refined today improves navigation in every future session, making the depth-scaling benefit permanent

Topics:
- [[graph-structure]]
