---
description: Three tiers (full automation, partial automation, minimal infrastructure) create a ceiling for features like pipelines, hooks, and semantic search, while core markdown conventions work universally
kind: research
topics: ["[[agent-cognition]]"]
methodology: ["Original"]
source: [[agent-platform-capabilities-research-source]]
---

# platform capability tiers determine which knowledge system features can be implemented

Not all agent platforms offer the same infrastructure, and this asymmetry directly constrains which knowledge system features can function on each platform. The useful framing organizes platforms into three capability tiers, each creating a different ceiling for what a knowledge system built on that platform can actually do.

The first tier provides full automation infrastructure: context files with read-write access, lifecycle hooks at multiple event boundaries, skills with context forking and model selection, subagent spawning with independent context windows, and MCP integration for external tools. Claude Code exemplifies this tier. A knowledge system built here can implement automated session orientation, processing pipelines with fresh context per phase, validation on every file write, and semantic search. The full Ars Contexta methodology -- skill-encoded quality gates, progressive disclosure via hooks, recursive self-extension -- operates at this tier because since [[context files function as agent operating systems through self-referential self-extension]], self-extension specifically requires the platform to grant write access to the context file that governs agent behavior.

The second tier provides partial automation: context files and some skill support but limited hooks, no native subagent spawning, and basic MCP integration. Cursor, Gemini CLI, and Codex fit here with varying feature profiles. A knowledge system on this tier can implement note templates, wiki links, MOCs, and YAML schemas, plus some skill-driven workflows, but loses the processing pipeline's isolation guarantee. Since [[fresh context per task preserves quality better than chaining phases]], the inability to spawn subagents means later pipeline phases run on degraded attention -- a quality loss that cannot be papered over with instruction-level workarounds.

The third tier provides minimal infrastructure: the agent can read instructions and execute file operations but lacks hooks, skills, and subagents. Any LLM with filesystem access fits here. The knowledge system reduces to core markdown conventions -- note templates, wiki links, MOCs, YAML frontmatter -- because since [[local-first file formats are inherently agent-native]], these features are just files and text that any agent reads without infrastructure.

The critical design insight is that these tiers create a composability requirement, not a binary adoption decision. Core features (yaml-schema, wiki-links, atomic-notes, mocs) work at every tier because they are markdown conventions requiring no platform capabilities. Advanced features (processing-pipeline, hooks, validation, semantic-search) require specific platform infrastructure. A knowledge system generator must detect the platform tier and offer only features the platform can actually support, rather than degrading gracefully from a full-feature assumption. The tier framework becomes more precise when crossed with since [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]]: tiers describe what platforms CAN do, layers describe what features NEED, and the intersection produces a capability matrix that maps exactly which features work where. The sharpest boundary in this matrix is the convention-to-automation layer transition, because since [[hook enforcement guarantees quality while instruction enforcement merely suggests it]], the jump from instruction compliance to hook enforcement is a categorical change in what the system can guarantee.

This means since [[knowledge system architecture is parameterized by platform capabilities not fixed by methodology]], the generator's job is not replicating a fixed design but parameterized production. Because [[eight configuration dimensions parameterize the space of possible knowledge systems]], the tiers directly constrain at least two dimensions — automation level (which IS the tier distinction) and processing intensity (which requires subagent infrastructure for heavy processing). The same methodology manifests differently at each tier because the infrastructure determines which positions along these dimensions are viable. But parameterization must be combined with restraint: since [[complex systems evolve from simple working systems]], the generator should target the minimum viable configuration for each tier rather than the maximum features the tier could theoretically support. A tier-one platform that could run twelve skills, five hooks, and three-phase parallel processing should still start simple and let friction determine what to add.

Even at tier one, capability is not unlimited. Since [[skill context budgets constrain knowledge system complexity on agent platforms]], the skill description budget (2% of context or 16,000 characters) caps active modules at roughly fifteen to twenty, meaning a tier-one platform cannot simply encode all methodology as skills -- the budget forces prioritization among workflows, and methodology that exceeds the budget falls back to instruction-level encoding with its weaker enforcement guarantees. The budget is a first-tier constraint: a problem you encounter precisely because you have the skill infrastructure, not despite it.

Even within a single tier, platforms differ in ways that matter. Since [[platform adapter translation is semantic not mechanical because hook event meanings differ]], translating automation-layer features between platforms at the same nominal tier requires decomposing quality guarantees into constituent properties rather than mechanically mapping event names. This maps to since [[data exit velocity measures how quickly content escapes vendor lock-in]]: tier-universal features align with high exit velocity (plain text, portable conventions), while tier-specific features introduce platform dependencies that lower exit velocity. The tension is productive: advanced features are genuinely valuable -- since [[skills encode methodology so manual execution bypasses quality gates]], losing skill infrastructure means losing the methodology itself, not just convenience. And since [[schema enforcement via validation agents enables soft consistency]], features like automated schema validation require tier-one hooks to guarantee enforcement -- at lower tiers, the same validation degrades to instruction-based compliance that provably drifts as context fills. But designing for universality means the core knowledge graph (notes, links, structure) survives platform transitions even when the automation layer does not. The self-improvement loop adds another dimension: since [[bootstrapping principle enables self-improving systems]], only tier-one platforms where the agent has write access to its own context file and infrastructure can close the recursive improvement loop. Lower tiers can operate knowledge systems but cannot evolve them -- the system stays as it was configured rather than adapting to discovered friction.

---
---

Relevant Notes:
- [[context files function as agent operating systems through self-referential self-extension]] — identifies the read-write vs read-only distinction that creates the sharpest tier boundary: self-extension requires write access to context files
- [[local-first file formats are inherently agent-native]] — explains why core features work at every tier: plain text with embedded metadata needs no platform infrastructure
- [[skills encode methodology so manual execution bypasses quality gates]] — illustrates what gets lost at lower tiers: not just automation convenience but the encoded quality gates that skills carry
- [[data exit velocity measures how quickly content escapes vendor lock-in]] — the portability metric that favors tier-universal features: high exit velocity maps to tier-independent functionality
- [[fresh context per task preserves quality better than chaining phases]] — a first-tier feature that cannot degrade gracefully: without subagent spawning, the processing pipeline loses its quality preservation mechanism
- [[four abstraction layers separate platform-agnostic from platform-dependent knowledge system features]] — the complementary decomposition: tiers describe what platforms CAN do, layers describe what features NEED; crossing them produces a capability matrix for mapping what works where
- [[hook enforcement guarantees quality while instruction enforcement merely suggests it]] — the hook-instruction gap defines the sharpest boundary between tiers one and two: the jump from suggested to guaranteed enforcement
- [[knowledge system architecture is parameterized by platform capabilities not fixed by methodology]] — the design consequence: tiers create the parameterization requirement because the same methodology manifests differently at each tier
- [[complex systems evolve from simple working systems]] — constrains how to start at each tier: Gall's Law says target the minimum viable configuration, not the maximum features the platform could theoretically support
- [[schema enforcement via validation agents enables soft consistency]] — a concrete automation-layer feature that requires tier-one hooks to guarantee enforcement; at lower tiers it degrades to instruction-based compliance that provably drifts
- [[platform fragmentation means identical conceptual operations require different implementations across agent environments]] — the implementation cost: even platforms at the same nominal tier implement capabilities differently enough that code sharing is minimal
- [[bootstrapping principle enables self-improving systems]] — the self-improvement loop only closes at tier one where the agent has write access to its own context file and can create infrastructure; lower tiers cannot bootstrap
- [[platform adapter translation is semantic not mechanical because hook event meanings differ]] — reveals that even within a tier, event semantics differ enough that translating automation-layer features between platforms requires decomposing quality guarantees rather than mechanical event-name mapping
- [[eight configuration dimensions parameterize the space of possible knowledge systems]] — the tiers directly constrain at least two of the eight dimensions: automation level IS the tier distinction, and processing intensity requires subagent infrastructure that only tier-one platforms provide
- [[skill context budgets constrain knowledge system complexity on agent platforms]] — first-tier constraint: the description budget caps active skills at 15-20, so even tier-one platforms cannot encode unlimited methodology as skills, creating a resource allocation problem within the most capable tier

Topics:
- [[agent-cognition]]
