---
description: Rosch's prototype theory predicts MOC titles work best at the "chair" level — specific enough to be informative, general enough to cover a cluster — and this level shifts as expertise deepens
kind: research
topics: ["[[graph-structure]]"]
methodology: ["Cognitive Science", "PKM Research"]
source: [[tft-research-part3]]
---

# basic level categorization determines optimal MOC granularity

Eleanor Rosch's prototype theory, developed through experiments in the 1970s, established that humans naturally categorize at a "basic level" that maximizes informativeness with minimum cognitive effort. The basic level sits between superordinate categories (too abstract to be useful) and subordinate categories (too specific to be general). "Chair" is basic level. "Furniture" is superordinate — it tells you almost nothing about what you're dealing with. "Kitchen chair" is subordinate — it adds detail that rarely matters for navigation.

This maps directly to MOC design. A MOC titled "tools" sits at the superordinate level: it covers everything and orients toward nothing. An agent loading a "tools" MOC gets a list so broad that the attention management benefit collapses — since [[MOCs are attention management devices not just organizational tools]], a superordinate MOC fails the orientation function because it presents too much unrelated content, forcing the agent to re-filter within the MOC itself. The attention tax that MOCs are supposed to eliminate gets relocated rather than reduced.

At the other extreme, a MOC titled "obsidian git plugin" sits at the subordinate level. It covers so little that the overhead of maintaining a separate MOC exceeds the navigation benefit. The agent must traverse multiple subordinate MOCs to build any picture of the domain, which creates exactly the kind of fragmented orientation that since [[navigational vertigo emerges in pure association systems without local hierarchy]] identifies as the core failure mode of under-structured systems. Too many tiny MOCs produce the same disorientation as no MOCs at all — landmarks only help when they're sparse enough to provide bearing.

The basic level is where MOC titles should sit: specific enough that loading the MOC tells you what the domain contains, general enough that a meaningful cluster of notes belongs there. "Graph structure," "agent cognition," "processing workflow" — these are basic-level categories in this vault. They name a domain you can reason about without being either uselessly abstract or unnecessarily narrow.

But Rosch's deeper finding complicates this. Basic level is not fixed — it shifts with expertise. A novice's basic level for biology is "fish." A marine biologist's basic level is "salmonid." As understanding deepens, what counts as the right categorization granularity moves downward because the expert has enough context to make finer distinctions meaningful. The subordinate category that was too narrow for a novice becomes informationally rich for an expert.

For vault MOCs, this means granularity should evolve with understanding, not just with volume. The vault's current split heuristic — CLAUDE.md prescribes splitting at 35-50 links — captures the volume dimension but misses the expertise dimension. A MOC might have only 25 notes but still benefit from splitting because the operator's understanding has deepened enough that the basic level has shifted. "Processing workflow" was basic level when the vault had a dozen notes about processing. Now, with distinct clusters around throughput, sessions, and forcing functions, the basic level has moved to "processing workflow throughput" — and the vault has already enacted this split, suggesting the principle operates even without being named. The deepening is not abstract — since [[incremental formalization happens through repeated touching of old notes]], each maintenance pass that sharpens a note also sharpens the operator's understanding of the domain, and it is precisely this accumulated understanding that makes the current MOC granularity feel inadequate and the finer distinctions feel necessary.

Since [[community detection algorithms can inform when MOCs should split or merge]], the algorithmic approach and the cognitive approach complement each other. Community detection reveals WHEN boundaries have shifted by identifying dense clusters within a MOC. Basic level theory explains WHERE those new boundaries should land — at the level that maximizes informativeness for the current depth of understanding. A Louvain algorithm might tell you that graph-structure has bifurcated. Rosch tells you that the sub-MOCs should be "link semantics" and "network topology," not "wiki links" (too narrow) or "knowledge organization" (too broad). The algorithm finds the clusters; the theory names them at the right level.

Since [[faceted classification treats notes as multi-dimensional objects rather than folder contents]], there is an interesting relationship between Ranganathan's framework and Rosch's. Faceted classification explains which AXES to categorize along (type, methodology, topic, role). Basic level theory explains what RESOLUTION to target on each axis. Together they predict that a well-designed classification system uses orthogonal facets at basic-level granularity — each dimension specific enough to filter meaningfully but general enough to group useful clusters.

The expertise-shift mechanism has a vocabulary parallel. Since [[narrow folksonomy optimizes for single-operator retrieval unlike broad consensus tagging]], personal vocabulary in a single-operator vault evolves toward increasingly precise distinctions as understanding deepens — the same operator who once tagged notes "knowledge management" begins distinguishing "capture patterns" from "retrieval mechanisms" from "maintenance scheduling." The vocabulary shift and the categorization shift are two expressions of the same underlying process: expertise making finer distinctions meaningful. Basic level theory predicts when MOC titles should split; narrow folksonomy predicts when the operator's vocabulary has already outgrown those titles.

This categorization judgment is exercised most visibly during MOC construction. Since [[MOC construction forces synthesis that automated generation from metadata cannot replicate]], the Lump phase of the Dump-Lump-Jump pattern IS basic level categorization in practice: the builder groups notes into clusters, decides which clusters deserve their own heading or sub-MOC, and senses the mental squeeze point where a single MOC becomes too coarse. Automated generation that matches notes to topics by metadata tags cannot perform this judgment because it has no mechanism to feel when the basic level has shifted — it classifies at whatever granularity the tags provide, regardless of whether that granularity serves the current understanding.

The practical implication for agents is a testable heuristic: when creating or splitting a MOC, ask whether the title sits at basic level. Can you complete the sentence "This MOC covers everything about [title]" and have the scope be neither uselessly broad nor trivially narrow? Does loading this MOC orient you to a domain, or does it either overwhelm with scope or underwhelm with specificity? The answer depends on the current state of understanding — which is why MOC granularity is a living design decision, not a one-time architectural choice.

---

Source: [[tft-research-part3]]
---

Relevant Notes:
- [[community detection algorithms can inform when MOCs should split or merge]] — algorithmic complement: community detection reveals WHEN boundaries should move, basic level theory explains WHERE they should land; the split signal from Louvain tells you a MOC has outgrown its category, basic level theory tells you what granularity the sub-MOCs should target
- [[MOCs are attention management devices not just organizational tools]] — explains the cost of getting granularity wrong: a MOC at the wrong level wastes attention either through overloaded context (too superordinate) or fragmented orientation (too subordinate)
- [[navigational vertigo emerges in pure association systems without local hierarchy]] — the failure mode that basic level targeting prevents: superordinate MOCs provide hierarchy but not useful landmarks, subordinate MOCs create too many landmarks to navigate between
- [[faceted classification treats notes as multi-dimensional objects rather than folder contents]] — complementary classification theory: Ranganathan explains the axes of classification, Rosch explains the optimal resolution along each axis
- [[progressive disclosure means reading right not reading less]] — MOC granularity determines disclosure effectiveness: a basic-level MOC loads the right amount of context for orientation, while superordinate MOCs load too broad a context and subordinate MOCs require loading multiple MOCs to orient
- [[narrow folksonomy optimizes for single-operator retrieval unlike broad consensus tagging]] — parallel expertise-driven evolution: as understanding deepens, personal vocabulary becomes more precise (narrow folksonomy) and categorization becomes more granular (basic level shift); both are expressions of expertise making finer distinctions meaningful
- [[incremental formalization happens through repeated touching of old notes]] — the mechanism that drives basic level shift: repeated touches deepen understanding, and that deepened understanding is what makes the current granularity feel too coarse and sub-MOCs feel necessary
- [[cross-links between MOC territories indicate creative leaps and integration depth]] — diagnostic signal: notes appearing in multiple MOCs may indicate a MOC sitting at the wrong granularity level, where basic-level sub-MOCs would better capture the distinct domains those cross-links bridge
- [[associative ontologies beat hierarchical taxonomies because heterarchy adapts while hierarchy brittles]] — foundation: basic level theory explains at what granularity the local hierarchy MOCs provide should operate within the heterarchical structure; MOCs are the controlled exception to pure association, and Rosch predicts their optimal resolution
- [[MOC construction forces synthesis that automated generation from metadata cannot replicate]] — domain application: the Lump phase of MOC construction IS basic level categorization in practice; the builder decides whether a cluster of notes deserves its own sub-MOC by sensing the mental squeeze point, and this granularity judgment is precisely what automated generation cannot perform because it requires the domain expertise that Rosch's basic level shift depends on

Topics:
- [[graph-structure]]
