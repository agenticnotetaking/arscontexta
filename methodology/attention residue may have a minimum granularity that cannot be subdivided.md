---
description: Micro-interruptions as brief as 2.8 seconds double error rates, suggesting an irreducible attention quantum below which no mitigation strategy — MOCs, batching, closure rituals — can prevent
kind: research
topics: ["[[agent-cognition]]", "[[processing-workflows]]"]
confidence: speculative
methodology: ["Cognitive Science"]
source: [[tft-research-part3]]
---

# attention residue may have a minimum granularity that cannot be subdivided

The vault's attention management architecture rests on a gradient assumption: context switching cost is a continuous variable that can be reduced through better design. MOCs reduce orientation cost. Batching reduces switching frequency. Closure rituals reduce residue bleed. Fresh context per task prevents degradation accumulation. Each mitigation shaves cost from the switching budget. But what if the cost function has a floor — an irreducible minimum below which no design optimization helps?

The evidence for a floor comes from micro-interruption research. Studies show that interruptions as brief as 2.8 seconds — barely long enough to read a notification — can double error rates on the primary task. This is not the 23-minute recovery time that Leroy documented for full task switches. This is a penalty that fires at a timescale so short that the subject has not meaningfully engaged with the interrupting task. The mere act of redirecting attention, even momentarily, exacts a cost that appears to be independent of the interruption's content or duration. If this holds, it suggests an attention quantum: a minimum unit of switching cost that cannot be subdivided further.

The implication for knowledge systems is uncomfortable. Since [[MOCs are attention management devices not just organizational tools]], MOCs compress orientation to reduce switching cost — but if the cost has a floor, MOCs can only reduce the variable component above that floor. The irreducible portion persists regardless of how well-designed the MOC is. Similarly, since [[batching by context similarity reduces switching costs in agent processing]], batching minimizes how often you switch and how far you switch, but each switch still pays the minimum cost. Even context-similar consecutive tasks incur the floor penalty at each boundary.

Since [[closure rituals create clean breaks that prevent attention residue bleed]], the vault treats residue as something that can be managed through explicit completion signals. But the micro-interruption research suggests that some residue is not about incomplete tasks or missing closure signals — it is about the attention mechanism itself requiring a minimum recovery period after any redirection, regardless of whether the interrupted task was properly closed. Closure rituals address volitional switching (choosing to end a task). The minimum granularity problem applies to involuntary attention capture (the notification that breaks focus whether you choose to engage or not). The distinction matters because the [[Zeigarnik effect validates capture-first philosophy because open loops drain attention]] through a continuous drain mechanism — the loop persists until closed — while the minimum granularity cost fires instantaneously at the moment of redirection and cannot be prevented by faster closure.

For agents, the question translates differently but remains meaningful. Since [[LLM attention degrades as context fills]], agents face their own switching costs when loading new context. Since [[fresh context per task preserves quality better than chaining phases]], session isolation is the primary mitigation. But even fresh sessions require an orientation phase — reading CLAUDE.md, loading the relevant MOC, understanding the task file. Since [[session boundary hooks implement cognitive bookends for orientation and reflection]], this orientation cost is concretely observable: the SessionStart hook loads file tree, health metrics, and queue status before any productive work begins, consuming a fixed token budget that cannot be eliminated no matter how well the hooks are designed. If there is a minimum cognitive warm-up cost that cannot be compressed below some threshold, then session isolation trades one cost (degradation from context accumulation) for another (irreducible orientation overhead per session). The tradeoff is still favorable, but it is not free.

The deeper tension is with the vault's implicit assumption that since [[notes function as cognitive anchors that stabilize attention during complex tasks]], sufficiently good anchoring can make switching nearly costless. If the minimum granularity thesis is correct, anchoring reduces the variable cost of reconstruction but cannot eliminate the fixed cost of redirection itself. The transition from one anchored state to another — from one topic's mental model to the next — has a floor cost that better anchors cannot reduce.

This is genuinely open because the micro-interruption research comes from human cognition, and the transfer to agent architectures is uncertain. LLM attention mechanisms do not have biological recovery times. A transformer does not need 2.8 seconds to reset after a context switch — it processes the new context in a single forward pass. However, the token cost of orientation (loading relevant context, priming the right conceptual frame) may function as an analogous minimum: there is a minimum number of tokens required to establish productive reasoning on any topic, and no optimization of MOC design or disclosure layers can push that number to zero. This matters for the broader paradigm shift: since [[AI shifts knowledge systems from externalizing memory to externalizing attention]], and since [[cognitive offloading is the architectural foundation for vault design]], the vault can offload the variable costs of attention management — what to attend to, when, in what order — but the fixed cost of redirecting attention itself resists externalization. You can offload the decision of where to look next, but not the cost of looking.

If the minimum granularity thesis holds, the design implication is to reduce switching frequency rather than switching cost. Rather than making each switch cheaper (which hits the floor), make fewer switches total. This strengthens the case for deeper sessions with larger task scopes over rapid task cycling — and creates tension with the session isolation architecture that favors many short, fresh sessions. It also creates tension with the philosophy that [[continuous small-batch processing eliminates review dread]], because if each batch boundary incurs an irreducible cost, the smallest possible batches may not be optimal — the orientation overhead per batch must be amortized across enough productive work to justify the switch. The resolution may lie in finding the right session granularity: large enough to amortize the irreducible orientation cost across productive work, small enough to stay in the smart zone.

---
---

Relevant Notes:
- [[closure rituals create clean breaks that prevent attention residue bleed]] — closure rituals address the residue from completed tasks, but this note questions whether some residue is irreducible regardless of how cleanly you close
- [[MOCs are attention management devices not just organizational tools]] — MOCs reduce orientation cost but cannot eliminate the fundamental switching penalty if the penalty has a non-zero floor
- [[batching by context similarity reduces switching costs in agent processing]] — batching minimizes switching frequency and severity, but if there is a minimum granularity, even context-similar batches still pay the irreducible cost at each boundary
- [[fresh context per task preserves quality better than chaining phases]] — session isolation is the macro-level response to attention degradation; this note asks whether even fresh sessions carry an irreducible orientation cost that cannot be eliminated
- [[notes function as cognitive anchors that stabilize attention during complex tasks]] — anchoring stabilizes attention during work, but the minimum granularity question asks whether the transition TO the anchored state itself has an irreducible cost
- [[LLM attention degrades as context fills]] — the attention degradation science this tension builds on; if degradation has a step function at micro-timescales rather than a smooth curve, mitigation strategies may face a hard floor
- [[AI shifts knowledge systems from externalizing memory to externalizing attention]] — if attention has an irreducible switching floor, then externalizing attention hits a harder limit than externalizing memory; you can offload what to attend to but not the fixed cost of redirecting attention itself
- [[cognitive offloading is the architectural foundation for vault design]] — offloading reduces variable costs (what to hold, where to look) but the minimum granularity thesis suggests the fixed cost of redirecting attention cannot be offloaded to any external system
- [[Zeigarnik effect validates capture-first philosophy because open loops drain attention]] — both identify irreducible attention costs from different mechanisms: Zeigarnik describes ongoing drain from unclosed loops, minimum granularity describes instantaneous cost from switching itself
- [[session boundary hooks implement cognitive bookends for orientation and reflection]] — bookend hooks are the concrete implementation of orientation overhead; the minimum granularity thesis asks whether there is a floor on that orientation cost that better hooks cannot compress
- [[continuous small-batch processing eliminates review dread]] — tension: if each batch boundary incurs an irreducible switching cost, optimal batch size must be large enough to amortize that cost, creating pressure against the smallest possible batches

Topics:
- [[agent-cognition]]
- [[processing-workflows]]
